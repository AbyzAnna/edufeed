{
  "version": 3,
  "sources": ["../../../node_modules/unenv/dist/runtime/_internal/utils.mjs", "../../../node_modules/unenv/dist/runtime/node/internal/perf_hooks/performance.mjs", "../../../node_modules/@cloudflare/unenv-preset/dist/runtime/polyfill/performance.mjs", "../../../node_modules/unenv/dist/runtime/node/console.mjs", "../../../node_modules/unenv/dist/runtime/mock/noop.mjs", "../../../node_modules/@cloudflare/unenv-preset/dist/runtime/node/console.mjs", "../../../node_modules/wrangler/_virtual_unenv_global_polyfill-@cloudflare-unenv-preset-node-console", "../../../node_modules/unenv/dist/runtime/node/internal/process/hrtime.mjs", "../../../node_modules/unenv/dist/runtime/node/internal/process/process.mjs", "../../../node_modules/unenv/dist/runtime/node/internal/tty/read-stream.mjs", "../../../node_modules/unenv/dist/runtime/node/internal/tty/write-stream.mjs", "../../../node_modules/unenv/dist/runtime/node/internal/process/node-version.mjs", "../../../node_modules/@cloudflare/unenv-preset/dist/runtime/node/process.mjs", "../../../node_modules/wrangler/_virtual_unenv_global_polyfill-@cloudflare-unenv-preset-node-process", "../../../workers/lib/embeddings.ts", "../../../workers/lib/llm.ts", "../../../workers/lib/chat.ts", "../../../workers/lib/study-guide.ts", "../../../workers/lib/flashcards.ts", "../../../workers/lib/audio-overview.ts", "../../../workers/index.ts", "../../../node_modules/wrangler/templates/middleware/middleware-ensure-req-body-drained.ts", "../../../node_modules/wrangler/templates/middleware/middleware-miniflare3-json-error.ts", "../bundle-e01auW/middleware-insertion-facade.js", "../../../node_modules/wrangler/templates/middleware/common.ts", "../bundle-e01auW/middleware-loader.entry.ts"],
  "sourceRoot": "/Users/annaabyzova/Projects/Website feed/.wrangler/tmp/dev-XK945M",
  "sourcesContent": ["/* @__NO_SIDE_EFFECTS__ */\nexport function rawHeaders(headers) {\n\tconst rawHeaders = [];\n\tfor (const key in headers) {\n\t\tif (Array.isArray(headers[key])) {\n\t\t\tfor (const h of headers[key]) {\n\t\t\t\trawHeaders.push(key, h);\n\t\t\t}\n\t\t} else {\n\t\t\trawHeaders.push(key, headers[key]);\n\t\t}\n\t}\n\treturn rawHeaders;\n}\n/* @__NO_SIDE_EFFECTS__ */\nexport function mergeFns(...functions) {\n\treturn function(...args) {\n\t\tfor (const fn of functions) {\n\t\t\tfn(...args);\n\t\t}\n\t};\n}\n/* @__NO_SIDE_EFFECTS__ */\nexport function createNotImplementedError(name) {\n\treturn new Error(`[unenv] ${name} is not implemented yet!`);\n}\n/* @__NO_SIDE_EFFECTS__ */\nexport function notImplemented(name) {\n\tconst fn = () => {\n\t\tthrow createNotImplementedError(name);\n\t};\n\treturn Object.assign(fn, { __unenv__: true });\n}\n/* @__NO_SIDE_EFFECTS__ */\nexport function notImplementedAsync(name) {\n\tconst fn = notImplemented(name);\n\tfn.__promisify__ = () => notImplemented(name + \".__promisify__\");\n\tfn.native = fn;\n\treturn fn;\n}\n/* @__NO_SIDE_EFFECTS__ */\nexport function notImplementedClass(name) {\n\treturn class {\n\t\t__unenv__ = true;\n\t\tconstructor() {\n\t\t\tthrow new Error(`[unenv] ${name} is not implemented yet!`);\n\t\t}\n\t};\n}\n", "import { createNotImplementedError } from \"../../../_internal/utils.mjs\";\nconst _timeOrigin = globalThis.performance?.timeOrigin ?? Date.now();\nconst _performanceNow = globalThis.performance?.now ? globalThis.performance.now.bind(globalThis.performance) : () => Date.now() - _timeOrigin;\nconst nodeTiming = {\n\tname: \"node\",\n\tentryType: \"node\",\n\tstartTime: 0,\n\tduration: 0,\n\tnodeStart: 0,\n\tv8Start: 0,\n\tbootstrapComplete: 0,\n\tenvironment: 0,\n\tloopStart: 0,\n\tloopExit: 0,\n\tidleTime: 0,\n\tuvMetricsInfo: {\n\t\tloopCount: 0,\n\t\tevents: 0,\n\t\teventsWaiting: 0\n\t},\n\tdetail: undefined,\n\ttoJSON() {\n\t\treturn this;\n\t}\n};\n// PerformanceEntry\nexport class PerformanceEntry {\n\t__unenv__ = true;\n\tdetail;\n\tentryType = \"event\";\n\tname;\n\tstartTime;\n\tconstructor(name, options) {\n\t\tthis.name = name;\n\t\tthis.startTime = options?.startTime || _performanceNow();\n\t\tthis.detail = options?.detail;\n\t}\n\tget duration() {\n\t\treturn _performanceNow() - this.startTime;\n\t}\n\ttoJSON() {\n\t\treturn {\n\t\t\tname: this.name,\n\t\t\tentryType: this.entryType,\n\t\t\tstartTime: this.startTime,\n\t\t\tduration: this.duration,\n\t\t\tdetail: this.detail\n\t\t};\n\t}\n}\n// PerformanceMark\nexport const PerformanceMark = class PerformanceMark extends PerformanceEntry {\n\tentryType = \"mark\";\n\tconstructor() {\n\t\t// @ts-ignore\n\t\tsuper(...arguments);\n\t}\n\tget duration() {\n\t\treturn 0;\n\t}\n};\n// PerformanceMark\nexport class PerformanceMeasure extends PerformanceEntry {\n\tentryType = \"measure\";\n}\n// PerformanceResourceTiming\nexport class PerformanceResourceTiming extends PerformanceEntry {\n\tentryType = \"resource\";\n\tserverTiming = [];\n\tconnectEnd = 0;\n\tconnectStart = 0;\n\tdecodedBodySize = 0;\n\tdomainLookupEnd = 0;\n\tdomainLookupStart = 0;\n\tencodedBodySize = 0;\n\tfetchStart = 0;\n\tinitiatorType = \"\";\n\tname = \"\";\n\tnextHopProtocol = \"\";\n\tredirectEnd = 0;\n\tredirectStart = 0;\n\trequestStart = 0;\n\tresponseEnd = 0;\n\tresponseStart = 0;\n\tsecureConnectionStart = 0;\n\tstartTime = 0;\n\ttransferSize = 0;\n\tworkerStart = 0;\n\tresponseStatus = 0;\n}\n// PerformanceObserverEntryList\nexport class PerformanceObserverEntryList {\n\t__unenv__ = true;\n\tgetEntries() {\n\t\treturn [];\n\t}\n\tgetEntriesByName(_name, _type) {\n\t\treturn [];\n\t}\n\tgetEntriesByType(type) {\n\t\treturn [];\n\t}\n}\n// Performance\nexport class Performance {\n\t__unenv__ = true;\n\ttimeOrigin = _timeOrigin;\n\teventCounts = new Map();\n\t_entries = [];\n\t_resourceTimingBufferSize = 0;\n\tnavigation = undefined;\n\ttiming = undefined;\n\ttimerify(_fn, _options) {\n\t\tthrow createNotImplementedError(\"Performance.timerify\");\n\t}\n\tget nodeTiming() {\n\t\treturn nodeTiming;\n\t}\n\teventLoopUtilization() {\n\t\treturn {};\n\t}\n\tmarkResourceTiming() {\n\t\t// TODO: create a new PerformanceResourceTiming entry\n\t\t// so that performance.getEntries, getEntriesByName, and getEntriesByType return it\n\t\t// see: https://nodejs.org/api/perf_hooks.html#performancemarkresourcetimingtiminginfo-requestedurl-initiatortype-global-cachemode-bodyinfo-responsestatus-deliverytype\n\t\treturn new PerformanceResourceTiming(\"\");\n\t}\n\tonresourcetimingbufferfull = null;\n\tnow() {\n\t\t// https://developer.mozilla.org/en-US/docs/Web/API/Performance/now\n\t\tif (this.timeOrigin === _timeOrigin) {\n\t\t\treturn _performanceNow();\n\t\t}\n\t\treturn Date.now() - this.timeOrigin;\n\t}\n\tclearMarks(markName) {\n\t\tthis._entries = markName ? this._entries.filter((e) => e.name !== markName) : this._entries.filter((e) => e.entryType !== \"mark\");\n\t}\n\tclearMeasures(measureName) {\n\t\tthis._entries = measureName ? this._entries.filter((e) => e.name !== measureName) : this._entries.filter((e) => e.entryType !== \"measure\");\n\t}\n\tclearResourceTimings() {\n\t\tthis._entries = this._entries.filter((e) => e.entryType !== \"resource\" || e.entryType !== \"navigation\");\n\t}\n\tgetEntries() {\n\t\treturn this._entries;\n\t}\n\tgetEntriesByName(name, type) {\n\t\treturn this._entries.filter((e) => e.name === name && (!type || e.entryType === type));\n\t}\n\tgetEntriesByType(type) {\n\t\treturn this._entries.filter((e) => e.entryType === type);\n\t}\n\tmark(name, options) {\n\t\t// @ts-expect-error constructor is not protected\n\t\tconst entry = new PerformanceMark(name, options);\n\t\tthis._entries.push(entry);\n\t\treturn entry;\n\t}\n\tmeasure(measureName, startOrMeasureOptions, endMark) {\n\t\tlet start;\n\t\tlet end;\n\t\tif (typeof startOrMeasureOptions === \"string\") {\n\t\t\tstart = this.getEntriesByName(startOrMeasureOptions, \"mark\")[0]?.startTime;\n\t\t\tend = this.getEntriesByName(endMark, \"mark\")[0]?.startTime;\n\t\t} else {\n\t\t\tstart = Number.parseFloat(startOrMeasureOptions?.start) || this.now();\n\t\t\tend = Number.parseFloat(startOrMeasureOptions?.end) || this.now();\n\t\t}\n\t\tconst entry = new PerformanceMeasure(measureName, {\n\t\t\tstartTime: start,\n\t\t\tdetail: {\n\t\t\t\tstart,\n\t\t\t\tend\n\t\t\t}\n\t\t});\n\t\tthis._entries.push(entry);\n\t\treturn entry;\n\t}\n\tsetResourceTimingBufferSize(maxSize) {\n\t\tthis._resourceTimingBufferSize = maxSize;\n\t}\n\taddEventListener(type, listener, options) {\n\t\tthrow createNotImplementedError(\"Performance.addEventListener\");\n\t}\n\tremoveEventListener(type, listener, options) {\n\t\tthrow createNotImplementedError(\"Performance.removeEventListener\");\n\t}\n\tdispatchEvent(event) {\n\t\tthrow createNotImplementedError(\"Performance.dispatchEvent\");\n\t}\n\ttoJSON() {\n\t\treturn this;\n\t}\n}\n// PerformanceObserver\nexport class PerformanceObserver {\n\t__unenv__ = true;\n\tstatic supportedEntryTypes = [];\n\t_callback = null;\n\tconstructor(callback) {\n\t\tthis._callback = callback;\n\t}\n\ttakeRecords() {\n\t\treturn [];\n\t}\n\tdisconnect() {\n\t\tthrow createNotImplementedError(\"PerformanceObserver.disconnect\");\n\t}\n\tobserve(options) {\n\t\tthrow createNotImplementedError(\"PerformanceObserver.observe\");\n\t}\n\tbind(fn) {\n\t\treturn fn;\n\t}\n\trunInAsyncScope(fn, thisArg, ...args) {\n\t\treturn fn.call(thisArg, ...args);\n\t}\n\tasyncId() {\n\t\treturn 0;\n\t}\n\ttriggerAsyncId() {\n\t\treturn 0;\n\t}\n\temitDestroy() {\n\t\treturn this;\n\t}\n}\n// workerd implements a subset of globalThis.performance (as of last check, only timeOrigin set to 0 + now() implemented)\n// We already use performance.now() from globalThis.performance, if provided (see top of this file)\n// If we detect this condition, we can just use polyfill instead.\nexport const performance = globalThis.performance && \"addEventListener\" in globalThis.performance ? globalThis.performance : new Performance();\n", "import {\n  performance,\n  Performance,\n  PerformanceEntry,\n  PerformanceMark,\n  PerformanceMeasure,\n  PerformanceObserver,\n  PerformanceObserverEntryList,\n  PerformanceResourceTiming\n} from \"node:perf_hooks\";\nglobalThis.performance = performance;\nglobalThis.Performance = Performance;\nglobalThis.PerformanceEntry = PerformanceEntry;\nglobalThis.PerformanceMark = PerformanceMark;\nglobalThis.PerformanceMeasure = PerformanceMeasure;\nglobalThis.PerformanceObserver = PerformanceObserver;\nglobalThis.PerformanceObserverEntryList = PerformanceObserverEntryList;\nglobalThis.PerformanceResourceTiming = PerformanceResourceTiming;\n", "import { Writable } from \"node:stream\";\nimport noop from \"../mock/noop.mjs\";\nimport { notImplemented, notImplementedClass } from \"../_internal/utils.mjs\";\nconst _console = globalThis.console;\n// undocumented public APIs\nexport const _ignoreErrors = true;\nexport const _stderr = new Writable();\nexport const _stdout = new Writable();\nexport const log = _console?.log ?? noop;\nexport const info = _console?.info ?? log;\nexport const trace = _console?.trace ?? info;\nexport const debug = _console?.debug ?? log;\nexport const table = _console?.table ?? log;\nexport const error = _console?.error ?? log;\nexport const warn = _console?.warn ?? error;\n// https://developer.chrome.com/docs/devtools/console/api#createtask\nexport const createTask = _console?.createTask ?? /* @__PURE__ */ notImplemented(\"console.createTask\");\nexport const assert = /* @__PURE__ */ notImplemented(\"console.assert\");\n// noop\nexport const clear = _console?.clear ?? noop;\nexport const count = _console?.count ?? noop;\nexport const countReset = _console?.countReset ?? noop;\nexport const dir = _console?.dir ?? noop;\nexport const dirxml = _console?.dirxml ?? noop;\nexport const group = _console?.group ?? noop;\nexport const groupEnd = _console?.groupEnd ?? noop;\nexport const groupCollapsed = _console?.groupCollapsed ?? noop;\nexport const profile = _console?.profile ?? noop;\nexport const profileEnd = _console?.profileEnd ?? noop;\nexport const time = _console?.time ?? noop;\nexport const timeEnd = _console?.timeEnd ?? noop;\nexport const timeLog = _console?.timeLog ?? noop;\nexport const timeStamp = _console?.timeStamp ?? noop;\nexport const Console = _console?.Console ?? /* @__PURE__ */ notImplementedClass(\"console.Console\");\nexport const _times = /* @__PURE__ */ new Map();\nexport function context() {\n\t// TODO: Should be Console with all the methods\n\treturn _console;\n}\nexport const _stdoutErrorHandler = noop;\nexport const _stderrErrorHandler = noop;\nexport default {\n\t_times,\n\t_ignoreErrors,\n\t_stdoutErrorHandler,\n\t_stderrErrorHandler,\n\t_stdout,\n\t_stderr,\n\tassert,\n\tclear,\n\tConsole,\n\tcount,\n\tcountReset,\n\tdebug,\n\tdir,\n\tdirxml,\n\terror,\n\tcontext,\n\tcreateTask,\n\tgroup,\n\tgroupEnd,\n\tgroupCollapsed,\n\tinfo,\n\tlog,\n\tprofile,\n\tprofileEnd,\n\ttable,\n\ttime,\n\ttimeEnd,\n\ttimeLog,\n\ttimeStamp,\n\ttrace,\n\twarn\n};\n", "export default Object.assign(() => {}, { __unenv__: true });\n", "import {\n  _ignoreErrors,\n  _stderr,\n  _stderrErrorHandler,\n  _stdout,\n  _stdoutErrorHandler,\n  _times,\n  Console\n} from \"unenv/node/console\";\nexport {\n  Console,\n  _ignoreErrors,\n  _stderr,\n  _stderrErrorHandler,\n  _stdout,\n  _stdoutErrorHandler,\n  _times\n} from \"unenv/node/console\";\nconst workerdConsole = globalThis[\"console\"];\nexport const {\n  assert,\n  clear,\n  // @ts-expect-error undocumented public API\n  context,\n  count,\n  countReset,\n  // @ts-expect-error undocumented public API\n  createTask,\n  debug,\n  dir,\n  dirxml,\n  error,\n  group,\n  groupCollapsed,\n  groupEnd,\n  info,\n  log,\n  profile,\n  profileEnd,\n  table,\n  time,\n  timeEnd,\n  timeLog,\n  timeStamp,\n  trace,\n  warn\n} = workerdConsole;\nObject.assign(workerdConsole, {\n  Console,\n  _ignoreErrors,\n  _stderr,\n  _stderrErrorHandler,\n  _stdout,\n  _stdoutErrorHandler,\n  _times\n});\nexport default workerdConsole;\n", "import { default as defaultExport } from \"@cloudflare/unenv-preset/node/console\";\nglobalThis.console = defaultExport;", "// https://nodejs.org/api/process.html#processhrtime\nexport const hrtime = /* @__PURE__ */ Object.assign(function hrtime(startTime) {\n\tconst now = Date.now();\n\t// millis to seconds\n\tconst seconds = Math.trunc(now / 1e3);\n\t// convert millis to nanos\n\tconst nanos = now % 1e3 * 1e6;\n\tif (startTime) {\n\t\tlet diffSeconds = seconds - startTime[0];\n\t\tlet diffNanos = nanos - startTime[0];\n\t\tif (diffNanos < 0) {\n\t\t\tdiffSeconds = diffSeconds - 1;\n\t\t\tdiffNanos = 1e9 + diffNanos;\n\t\t}\n\t\treturn [diffSeconds, diffNanos];\n\t}\n\treturn [seconds, nanos];\n}, { bigint: function bigint() {\n\t// Convert milliseconds to nanoseconds\n\treturn BigInt(Date.now() * 1e6);\n} });\n", "import { EventEmitter } from \"node:events\";\nimport { ReadStream, WriteStream } from \"node:tty\";\nimport { notImplemented, createNotImplementedError } from \"../../../_internal/utils.mjs\";\n// node-version.ts is generated at build time\nimport { NODE_VERSION } from \"./node-version.mjs\";\nexport class Process extends EventEmitter {\n\tenv;\n\thrtime;\n\tnextTick;\n\tconstructor(impl) {\n\t\tsuper();\n\t\tthis.env = impl.env;\n\t\tthis.hrtime = impl.hrtime;\n\t\tthis.nextTick = impl.nextTick;\n\t\tfor (const prop of [...Object.getOwnPropertyNames(Process.prototype), ...Object.getOwnPropertyNames(EventEmitter.prototype)]) {\n\t\t\tconst value = this[prop];\n\t\t\tif (typeof value === \"function\") {\n\t\t\t\tthis[prop] = value.bind(this);\n\t\t\t}\n\t\t}\n\t}\n\t// --- event emitter ---\n\temitWarning(warning, type, code) {\n\t\tconsole.warn(`${code ? `[${code}] ` : \"\"}${type ? `${type}: ` : \"\"}${warning}`);\n\t}\n\temit(...args) {\n\t\t// @ts-ignore\n\t\treturn super.emit(...args);\n\t}\n\tlisteners(eventName) {\n\t\treturn super.listeners(eventName);\n\t}\n\t// --- stdio (lazy initializers) ---\n\t#stdin;\n\t#stdout;\n\t#stderr;\n\tget stdin() {\n\t\treturn this.#stdin ??= new ReadStream(0);\n\t}\n\tget stdout() {\n\t\treturn this.#stdout ??= new WriteStream(1);\n\t}\n\tget stderr() {\n\t\treturn this.#stderr ??= new WriteStream(2);\n\t}\n\t// --- cwd ---\n\t#cwd = \"/\";\n\tchdir(cwd) {\n\t\tthis.#cwd = cwd;\n\t}\n\tcwd() {\n\t\treturn this.#cwd;\n\t}\n\t// --- dummy props and getters ---\n\tarch = \"\";\n\tplatform = \"\";\n\targv = [];\n\targv0 = \"\";\n\texecArgv = [];\n\texecPath = \"\";\n\ttitle = \"\";\n\tpid = 200;\n\tppid = 100;\n\tget version() {\n\t\treturn `v${NODE_VERSION}`;\n\t}\n\tget versions() {\n\t\treturn { node: NODE_VERSION };\n\t}\n\tget allowedNodeEnvironmentFlags() {\n\t\treturn new Set();\n\t}\n\tget sourceMapsEnabled() {\n\t\treturn false;\n\t}\n\tget debugPort() {\n\t\treturn 0;\n\t}\n\tget throwDeprecation() {\n\t\treturn false;\n\t}\n\tget traceDeprecation() {\n\t\treturn false;\n\t}\n\tget features() {\n\t\treturn {};\n\t}\n\tget release() {\n\t\treturn {};\n\t}\n\tget connected() {\n\t\treturn false;\n\t}\n\tget config() {\n\t\treturn {};\n\t}\n\tget moduleLoadList() {\n\t\treturn [];\n\t}\n\tconstrainedMemory() {\n\t\treturn 0;\n\t}\n\tavailableMemory() {\n\t\treturn 0;\n\t}\n\tuptime() {\n\t\treturn 0;\n\t}\n\tresourceUsage() {\n\t\treturn {};\n\t}\n\t// --- noop methods ---\n\tref() {\n\t\t// noop\n\t}\n\tunref() {\n\t\t// noop\n\t}\n\t// --- unimplemented methods ---\n\tumask() {\n\t\tthrow createNotImplementedError(\"process.umask\");\n\t}\n\tgetBuiltinModule() {\n\t\treturn undefined;\n\t}\n\tgetActiveResourcesInfo() {\n\t\tthrow createNotImplementedError(\"process.getActiveResourcesInfo\");\n\t}\n\texit() {\n\t\tthrow createNotImplementedError(\"process.exit\");\n\t}\n\treallyExit() {\n\t\tthrow createNotImplementedError(\"process.reallyExit\");\n\t}\n\tkill() {\n\t\tthrow createNotImplementedError(\"process.kill\");\n\t}\n\tabort() {\n\t\tthrow createNotImplementedError(\"process.abort\");\n\t}\n\tdlopen() {\n\t\tthrow createNotImplementedError(\"process.dlopen\");\n\t}\n\tsetSourceMapsEnabled() {\n\t\tthrow createNotImplementedError(\"process.setSourceMapsEnabled\");\n\t}\n\tloadEnvFile() {\n\t\tthrow createNotImplementedError(\"process.loadEnvFile\");\n\t}\n\tdisconnect() {\n\t\tthrow createNotImplementedError(\"process.disconnect\");\n\t}\n\tcpuUsage() {\n\t\tthrow createNotImplementedError(\"process.cpuUsage\");\n\t}\n\tsetUncaughtExceptionCaptureCallback() {\n\t\tthrow createNotImplementedError(\"process.setUncaughtExceptionCaptureCallback\");\n\t}\n\thasUncaughtExceptionCaptureCallback() {\n\t\tthrow createNotImplementedError(\"process.hasUncaughtExceptionCaptureCallback\");\n\t}\n\tinitgroups() {\n\t\tthrow createNotImplementedError(\"process.initgroups\");\n\t}\n\topenStdin() {\n\t\tthrow createNotImplementedError(\"process.openStdin\");\n\t}\n\tassert() {\n\t\tthrow createNotImplementedError(\"process.assert\");\n\t}\n\tbinding() {\n\t\tthrow createNotImplementedError(\"process.binding\");\n\t}\n\t// --- attached interfaces ---\n\tpermission = { has: /* @__PURE__ */ notImplemented(\"process.permission.has\") };\n\treport = {\n\t\tdirectory: \"\",\n\t\tfilename: \"\",\n\t\tsignal: \"SIGUSR2\",\n\t\tcompact: false,\n\t\treportOnFatalError: false,\n\t\treportOnSignal: false,\n\t\treportOnUncaughtException: false,\n\t\tgetReport: /* @__PURE__ */ notImplemented(\"process.report.getReport\"),\n\t\twriteReport: /* @__PURE__ */ notImplemented(\"process.report.writeReport\")\n\t};\n\tfinalization = {\n\t\tregister: /* @__PURE__ */ notImplemented(\"process.finalization.register\"),\n\t\tunregister: /* @__PURE__ */ notImplemented(\"process.finalization.unregister\"),\n\t\tregisterBeforeExit: /* @__PURE__ */ notImplemented(\"process.finalization.registerBeforeExit\")\n\t};\n\tmemoryUsage = Object.assign(() => ({\n\t\tarrayBuffers: 0,\n\t\trss: 0,\n\t\texternal: 0,\n\t\theapTotal: 0,\n\t\theapUsed: 0\n\t}), { rss: () => 0 });\n\t// --- undefined props ---\n\tmainModule = undefined;\n\tdomain = undefined;\n\t// optional\n\tsend = undefined;\n\texitCode = undefined;\n\tchannel = undefined;\n\tgetegid = undefined;\n\tgeteuid = undefined;\n\tgetgid = undefined;\n\tgetgroups = undefined;\n\tgetuid = undefined;\n\tsetegid = undefined;\n\tseteuid = undefined;\n\tsetgid = undefined;\n\tsetgroups = undefined;\n\tsetuid = undefined;\n\t// internals\n\t_events = undefined;\n\t_eventsCount = undefined;\n\t_exiting = undefined;\n\t_maxListeners = undefined;\n\t_debugEnd = undefined;\n\t_debugProcess = undefined;\n\t_fatalException = undefined;\n\t_getActiveHandles = undefined;\n\t_getActiveRequests = undefined;\n\t_kill = undefined;\n\t_preload_modules = undefined;\n\t_rawDebug = undefined;\n\t_startProfilerIdleNotifier = undefined;\n\t_stopProfilerIdleNotifier = undefined;\n\t_tickCallback = undefined;\n\t_disconnect = undefined;\n\t_handleQueue = undefined;\n\t_pendingMessage = undefined;\n\t_channel = undefined;\n\t_send = undefined;\n\t_linkedBinding = undefined;\n}\n", "export class ReadStream {\n\tfd;\n\tisRaw = false;\n\tisTTY = false;\n\tconstructor(fd) {\n\t\tthis.fd = fd;\n\t}\n\tsetRawMode(mode) {\n\t\tthis.isRaw = mode;\n\t\treturn this;\n\t}\n}\n", "export class WriteStream {\n\tfd;\n\tcolumns = 80;\n\trows = 24;\n\tisTTY = false;\n\tconstructor(fd) {\n\t\tthis.fd = fd;\n\t}\n\tclearLine(dir, callback) {\n\t\tcallback && callback();\n\t\treturn false;\n\t}\n\tclearScreenDown(callback) {\n\t\tcallback && callback();\n\t\treturn false;\n\t}\n\tcursorTo(x, y, callback) {\n\t\tcallback && typeof callback === \"function\" && callback();\n\t\treturn false;\n\t}\n\tmoveCursor(dx, dy, callback) {\n\t\tcallback && callback();\n\t\treturn false;\n\t}\n\tgetColorDepth(env) {\n\t\treturn 1;\n\t}\n\thasColors(count, env) {\n\t\treturn false;\n\t}\n\tgetWindowSize() {\n\t\treturn [this.columns, this.rows];\n\t}\n\twrite(str, encoding, cb) {\n\t\tif (str instanceof Uint8Array) {\n\t\t\tstr = new TextDecoder().decode(str);\n\t\t}\n\t\ttry {\n\t\t\tconsole.log(str);\n\t\t} catch {}\n\t\tcb && typeof cb === \"function\" && cb();\n\t\treturn false;\n\t}\n}\n", "// Extracted from .nvmrc\nexport const NODE_VERSION = \"22.14.0\";\n", "import { hrtime as UnenvHrTime } from \"unenv/node/internal/process/hrtime\";\nimport { Process as UnenvProcess } from \"unenv/node/internal/process/process\";\nconst globalProcess = globalThis[\"process\"];\nexport const getBuiltinModule = globalProcess.getBuiltinModule;\nconst workerdProcess = getBuiltinModule(\"node:process\");\nconst isWorkerdProcessV2 = globalThis.Cloudflare.compatibilityFlags.enable_nodejs_process_v2;\nconst unenvProcess = new UnenvProcess({\n  env: globalProcess.env,\n  // `hrtime` is only available from workerd process v2\n  hrtime: isWorkerdProcessV2 ? workerdProcess.hrtime : UnenvHrTime,\n  // `nextTick` is available from workerd process v1\n  nextTick: workerdProcess.nextTick\n});\nexport const { exit, features, platform } = workerdProcess;\nexport const {\n  // Always implemented by workerd\n  env,\n  // Only implemented in workerd v2\n  hrtime,\n  // Always implemented by workerd\n  nextTick\n} = unenvProcess;\nexport const {\n  _channel,\n  _disconnect,\n  _events,\n  _eventsCount,\n  _handleQueue,\n  _maxListeners,\n  _pendingMessage,\n  _send,\n  assert,\n  disconnect,\n  mainModule\n} = unenvProcess;\nexport const {\n  // @ts-expect-error `_debugEnd` is missing typings\n  _debugEnd,\n  // @ts-expect-error `_debugProcess` is missing typings\n  _debugProcess,\n  // @ts-expect-error `_exiting` is missing typings\n  _exiting,\n  // @ts-expect-error `_fatalException` is missing typings\n  _fatalException,\n  // @ts-expect-error `_getActiveHandles` is missing typings\n  _getActiveHandles,\n  // @ts-expect-error `_getActiveRequests` is missing typings\n  _getActiveRequests,\n  // @ts-expect-error `_kill` is missing typings\n  _kill,\n  // @ts-expect-error `_linkedBinding` is missing typings\n  _linkedBinding,\n  // @ts-expect-error `_preload_modules` is missing typings\n  _preload_modules,\n  // @ts-expect-error `_rawDebug` is missing typings\n  _rawDebug,\n  // @ts-expect-error `_startProfilerIdleNotifier` is missing typings\n  _startProfilerIdleNotifier,\n  // @ts-expect-error `_stopProfilerIdleNotifier` is missing typings\n  _stopProfilerIdleNotifier,\n  // @ts-expect-error `_tickCallback` is missing typings\n  _tickCallback,\n  abort,\n  addListener,\n  allowedNodeEnvironmentFlags,\n  arch,\n  argv,\n  argv0,\n  availableMemory,\n  // @ts-expect-error `binding` is missing typings\n  binding,\n  channel,\n  chdir,\n  config,\n  connected,\n  constrainedMemory,\n  cpuUsage,\n  cwd,\n  debugPort,\n  dlopen,\n  // @ts-expect-error `domain` is missing typings\n  domain,\n  emit,\n  emitWarning,\n  eventNames,\n  execArgv,\n  execPath,\n  exitCode,\n  finalization,\n  getActiveResourcesInfo,\n  getegid,\n  geteuid,\n  getgid,\n  getgroups,\n  getMaxListeners,\n  getuid,\n  hasUncaughtExceptionCaptureCallback,\n  // @ts-expect-error `initgroups` is missing typings\n  initgroups,\n  kill,\n  listenerCount,\n  listeners,\n  loadEnvFile,\n  memoryUsage,\n  // @ts-expect-error `moduleLoadList` is missing typings\n  moduleLoadList,\n  off,\n  on,\n  once,\n  // @ts-expect-error `openStdin` is missing typings\n  openStdin,\n  permission,\n  pid,\n  ppid,\n  prependListener,\n  prependOnceListener,\n  rawListeners,\n  // @ts-expect-error `reallyExit` is missing typings\n  reallyExit,\n  ref,\n  release,\n  removeAllListeners,\n  removeListener,\n  report,\n  resourceUsage,\n  send,\n  setegid,\n  seteuid,\n  setgid,\n  setgroups,\n  setMaxListeners,\n  setSourceMapsEnabled,\n  setuid,\n  setUncaughtExceptionCaptureCallback,\n  sourceMapsEnabled,\n  stderr,\n  stdin,\n  stdout,\n  throwDeprecation,\n  title,\n  traceDeprecation,\n  umask,\n  unref,\n  uptime,\n  version,\n  versions\n} = isWorkerdProcessV2 ? workerdProcess : unenvProcess;\nconst _process = {\n  abort,\n  addListener,\n  allowedNodeEnvironmentFlags,\n  hasUncaughtExceptionCaptureCallback,\n  setUncaughtExceptionCaptureCallback,\n  loadEnvFile,\n  sourceMapsEnabled,\n  arch,\n  argv,\n  argv0,\n  chdir,\n  config,\n  connected,\n  constrainedMemory,\n  availableMemory,\n  cpuUsage,\n  cwd,\n  debugPort,\n  dlopen,\n  disconnect,\n  emit,\n  emitWarning,\n  env,\n  eventNames,\n  execArgv,\n  execPath,\n  exit,\n  finalization,\n  features,\n  getBuiltinModule,\n  getActiveResourcesInfo,\n  getMaxListeners,\n  hrtime,\n  kill,\n  listeners,\n  listenerCount,\n  memoryUsage,\n  nextTick,\n  on,\n  off,\n  once,\n  pid,\n  platform,\n  ppid,\n  prependListener,\n  prependOnceListener,\n  rawListeners,\n  release,\n  removeAllListeners,\n  removeListener,\n  report,\n  resourceUsage,\n  setMaxListeners,\n  setSourceMapsEnabled,\n  stderr,\n  stdin,\n  stdout,\n  title,\n  throwDeprecation,\n  traceDeprecation,\n  umask,\n  uptime,\n  version,\n  versions,\n  // @ts-expect-error old API\n  domain,\n  initgroups,\n  moduleLoadList,\n  reallyExit,\n  openStdin,\n  assert,\n  binding,\n  send,\n  exitCode,\n  channel,\n  getegid,\n  geteuid,\n  getgid,\n  getgroups,\n  getuid,\n  setegid,\n  seteuid,\n  setgid,\n  setgroups,\n  setuid,\n  permission,\n  mainModule,\n  _events,\n  _eventsCount,\n  _exiting,\n  _maxListeners,\n  _debugEnd,\n  _debugProcess,\n  _fatalException,\n  _getActiveHandles,\n  _getActiveRequests,\n  _kill,\n  _preload_modules,\n  _rawDebug,\n  _startProfilerIdleNotifier,\n  _stopProfilerIdleNotifier,\n  _tickCallback,\n  _disconnect,\n  _handleQueue,\n  _pendingMessage,\n  _channel,\n  _send,\n  _linkedBinding\n};\nexport default _process;\n", "import { default as defaultExport } from \"@cloudflare/unenv-preset/node/process\";\nglobalThis.process = defaultExport;", "import type { Env, DocumentChunk } from '../types/env';\n\n/**\n * Generate embeddings for text using Cloudflare Workers AI\n * Uses @cf/baai/bge-large-en-v1.5 model (1024 dimensions)\n */\nexport async function generateEmbedding(\n  text: string,\n  env: Env\n): Promise<number[]> {\n  const response = await env.AI.run('@cf/baai/bge-large-en-v1.5', {\n    text: [text],\n  });\n\n  return response.data[0];\n}\n\n/**\n * Generate embeddings for multiple texts in batch\n */\nexport async function generateEmbeddings(\n  texts: string[],\n  env: Env\n): Promise<number[][]> {\n  // Workers AI supports batch processing\n  const response = await env.AI.run('@cf/baai/bge-large-en-v1.5', {\n    text: texts,\n  });\n\n  return response.data;\n}\n\n/**\n * Chunk document into smaller pieces for embedding\n * Uses recursive character text splitting\n */\nexport function chunkDocument(\n  content: string,\n  chunkSize: number = 1000,\n  chunkOverlap: number = 200\n): string[] {\n  const chunks: string[] = [];\n  let start = 0;\n\n  while (start < content.length) {\n    const end = Math.min(start + chunkSize, content.length);\n    const chunk = content.slice(start, end);\n\n    // Try to break at sentence boundaries\n    if (end < content.length) {\n      const lastPeriod = chunk.lastIndexOf('.');\n      const lastNewline = chunk.lastIndexOf('\\n');\n      const breakPoint = Math.max(lastPeriod, lastNewline);\n\n      if (breakPoint > chunkSize * 0.5) {\n        chunks.push(content.slice(start, start + breakPoint + 1));\n        start += breakPoint + 1 - chunkOverlap;\n        continue;\n      }\n    }\n\n    chunks.push(chunk);\n    start += chunkSize - chunkOverlap;\n  }\n\n  return chunks;\n}\n\n/**\n * Store document chunks with embeddings in Vectorize\n */\nexport async function storeDocumentEmbeddings(\n  sourceId: string,\n  content: string,\n  metadata: { title: string; type: string },\n  env: Env\n): Promise<void> {\n  // Chunk the document\n  const chunks = chunkDocument(content);\n\n  // Generate embeddings in batches\n  const batchSize = 10;\n  for (let i = 0; i < chunks.length; i += batchSize) {\n    const batch = chunks.slice(i, i + batchSize);\n    const embeddings = await generateEmbeddings(batch, env);\n\n    // Prepare vectors for insertion\n    const vectors = batch.map((chunk, idx) => ({\n      id: `${sourceId}-chunk-${i + idx}`,\n      values: embeddings[idx],\n      metadata: {\n        sourceId,\n        content: chunk,\n        chunkIndex: i + idx,\n        title: metadata.title,\n        type: metadata.type,\n      },\n    }));\n\n    // Insert into Vectorize\n    await env.VECTORIZE.upsert(vectors);\n  }\n}\n\n/**\n * Search for relevant document chunks using semantic search\n */\nexport async function searchRelevantChunks(\n  query: string,\n  sourceId: string | null,\n  topK: number = 5,\n  env: Env\n): Promise<DocumentChunk[]> {\n  // Generate embedding for the query\n  const queryEmbedding = await generateEmbedding(query, env);\n\n  // Search in Vectorize\n  const results = await env.VECTORIZE.query(queryEmbedding, {\n    topK,\n    filter: sourceId ? { sourceId } : undefined,\n  });\n\n  // Convert results to DocumentChunk format\n  return results.matches.map((match) => ({\n    id: match.id,\n    sourceId: match.metadata.sourceId as string,\n    content: match.metadata.content as string,\n    embedding: match.vector,\n    metadata: {\n      page: match.metadata.page as number | undefined,\n      timestamp: match.metadata.timestamp as number | undefined,\n      section: match.metadata.section as string | undefined,\n    },\n  }));\n}\n\n/**\n * Delete all embeddings for a source\n */\nexport async function deleteSourceEmbeddings(\n  sourceId: string,\n  env: Env\n): Promise<void> {\n  // Vectorize doesn't have direct delete by metadata yet\n  // We'll need to fetch all IDs first then delete\n  const results = await env.VECTORIZE.query(new Array(1024).fill(0), {\n    topK: 1000,\n    filter: { sourceId },\n  });\n\n  const ids = results.matches.map((m) => m.id);\n  if (ids.length > 0) {\n    await env.VECTORIZE.deleteByIds(ids);\n  }\n}\n", "import type { Env, Message } from '../types/env';\n\n/**\n * Call Llama 3.3 70B model via Cloudflare Workers AI\n */\nexport async function generateText(\n  prompt: string,\n  systemPrompt?: string,\n  env?: Env,\n  options: {\n    temperature?: number;\n    maxTokens?: number;\n    stream?: boolean;\n  } = {}\n): Promise<string> {\n  if (!env) {\n    throw new Error('Environment not provided');\n  }\n\n  const messages: Message[] = [];\n\n  if (systemPrompt) {\n    messages.push({\n      role: 'system',\n      content: systemPrompt,\n    });\n  }\n\n  messages.push({\n    role: 'user',\n    content: prompt,\n  });\n\n  const response = await env.AI.run('@cf/meta/llama-3.3-70b-instruct-fp8-fast', {\n    messages,\n    temperature: options.temperature ?? 0.7,\n    max_tokens: options.maxTokens ?? 2048,\n    stream: options.stream ?? false,\n  });\n\n  if (options.stream) {\n    // Handle streaming response\n    return response as unknown as string;\n  }\n\n  return response.response;\n}\n\n/**\n * Generate with conversation history\n */\nexport async function generateWithHistory(\n  messages: Message[],\n  env: Env,\n  options: {\n    temperature?: number;\n    maxTokens?: number;\n  } = {}\n): Promise<string> {\n  const response = await env.AI.run('@cf/meta/llama-3.3-70b-instruct-fp8-fast', {\n    messages,\n    temperature: options.temperature ?? 0.7,\n    max_tokens: options.maxTokens ?? 2048,\n  });\n\n  return response.response;\n}\n\n/**\n * Generate structured JSON output\n */\nexport async function generateJSON<T>(\n  prompt: string,\n  systemPrompt: string,\n  jsonSchema: string,\n  env: Env\n): Promise<T> {\n  const fullPrompt = `${prompt}\\n\\nYou MUST respond with valid JSON matching this schema:\\n${jsonSchema}`;\n\n  const response = await generateText(fullPrompt, systemPrompt, env, {\n    temperature: 0.3, // Lower temperature for more structured output\n  });\n\n  // Extract JSON from response (sometimes LLMs add markdown formatting)\n  const jsonMatch = response.match(/```json\\n([\\s\\S]*?)\\n```/) || response.match(/\\{[\\s\\S]*\\}/);\n\n  if (!jsonMatch) {\n    throw new Error('Failed to extract JSON from response');\n  }\n\n  const jsonStr = jsonMatch[1] || jsonMatch[0];\n  return JSON.parse(jsonStr) as T;\n}\n\n/**\n * Summarize text\n */\nexport async function summarize(\n  text: string,\n  maxLength: number = 500,\n  env: Env\n): Promise<string> {\n  const systemPrompt = `You are an expert at creating concise, informative summaries.\nSummarize the following text in approximately ${maxLength} characters.\nFocus on key points, main ideas, and important details.`;\n\n  return generateText(text, systemPrompt, env, {\n    temperature: 0.5,\n    maxTokens: Math.ceil(maxLength / 3), // Rough token estimate\n  });\n}\n\n/**\n * Extract key points from text\n */\nexport async function extractKeyPoints(\n  text: string,\n  count: number = 5,\n  env: Env\n): Promise<string[]> {\n  const systemPrompt = `You are an expert at identifying key information.\nExtract exactly ${count} key points from the following text.\nReturn only a JSON array of strings, each representing one key point.`;\n\n  const prompt = `Text to analyze:\\n\\n${text}`;\n\n  const jsonSchema = `[\"key point 1\", \"key point 2\", ...]`;\n\n  return generateJSON<string[]>(prompt, systemPrompt, jsonSchema, env);\n}\n\n/**\n * Generate questions from content\n */\nexport async function generateQuestions(\n  content: string,\n  count: number = 5,\n  difficulty: 'easy' | 'medium' | 'hard' = 'medium',\n  env: Env\n): Promise<Array<{ question: string; answer: string }>> {\n  const systemPrompt = `You are an expert educator creating study questions.\nGenerate exactly ${count} ${difficulty} difficulty questions based on the content.\nEach question should have a clear, concise answer.`;\n\n  const jsonSchema = `[{\"question\": \"...\", \"answer\": \"...\"}]`;\n\n  return generateJSON(content, systemPrompt, jsonSchema, env);\n}\n\n/**\n * Detect language and translate if needed\n */\nexport async function detectAndTranslate(\n  text: string,\n  targetLanguage: string = 'en',\n  env: Env\n): Promise<{ detected: string; translated?: string }> {\n  const systemPrompt = `Detect the language of the following text.\nIf it's not ${targetLanguage}, translate it to ${targetLanguage}.\nRespond with JSON: {\"language\": \"detected_language\", \"translation\": \"translated_text_if_needed\"}`;\n\n  return generateJSON(text, systemPrompt, '{\"language\": \"en\", \"translation\": \"...\"}', env);\n}\n", "import type { Env, ChatRequest, ChatResponse, Message, SourceCitation } from '../types/env';\nimport { searchRelevantChunks } from './embeddings';\nimport { generateWithHistory } from './llm';\n\n/**\n * RAG-based chat with documents\n * Implements NotebookLM-style Q&A with source citations\n */\nexport async function chatWithDocument(\n  request: ChatRequest,\n  env: Env\n): Promise<ChatResponse> {\n  const { sourceId, message, conversationHistory = [] } = request;\n\n  // 1. Search for relevant chunks using semantic search\n  const relevantChunks = await searchRelevantChunks(message, sourceId, 5, env);\n\n  // 2. Build context from relevant chunks\n  const context = relevantChunks\n    .map((chunk, idx) => `[Source ${idx + 1}]\\n${chunk.content}`)\n    .join('\\n\\n');\n\n  // 3. Build system prompt\n  const systemPrompt = `You are a helpful AI assistant that answers questions based on provided documents.\nUse the following context to answer the user's question accurately.\nAlways cite your sources by referencing [Source N] in your answer.\nIf the context doesn't contain enough information, say so clearly.\n\nContext:\n${context}\n\nGuidelines:\n- Be concise but comprehensive\n- Use bullet points for lists\n- Quote directly when appropriate\n- Always cite sources with [Source N]\n- If information is not in context, clearly state that`;\n\n  // 4. Build conversation with context\n  const messages: Message[] = [\n    { role: 'system', content: systemPrompt },\n    ...conversationHistory,\n    { role: 'user', content: message },\n  ];\n\n  // 5. Generate response\n  const response = await generateWithHistory(messages, env, {\n    temperature: 0.7,\n    maxTokens: 1500,\n  });\n\n  // 6. Extract source citations from response\n  const sources: SourceCitation[] = relevantChunks.map((chunk, idx) => ({\n    sourceId: chunk.sourceId,\n    chunk: chunk.content.substring(0, 200) + '...',\n    page: chunk.metadata.page,\n    timestamp: chunk.metadata.timestamp,\n    relevance: (5 - idx) / 5, // Simple relevance score based on ranking\n  }));\n\n  // 7. Generate conversation ID (in production, store in KV or D1)\n  const conversationId = crypto.randomUUID();\n\n  return {\n    response,\n    sources,\n    conversationId,\n  };\n}\n\n/**\n * Multi-turn conversation with context retention\n */\nexport async function continueChatConversation(\n  conversationId: string,\n  message: string,\n  env: Env\n): Promise<ChatResponse> {\n  // Retrieve conversation history from KV\n  const historyKey = `chat:${conversationId}`;\n  const historyJson = await env.CACHE.get(historyKey);\n\n  const conversationHistory: Message[] = historyJson ? JSON.parse(historyJson) : [];\n\n  // Get the source ID from the first message metadata (stored separately)\n  const metadataKey = `chat:meta:${conversationId}`;\n  const metadataJson = await env.CACHE.get(metadataKey);\n  const metadata = metadataJson ? JSON.parse(metadataJson) : {};\n\n  const sourceId = metadata.sourceId;\n\n  // Continue the conversation\n  const response = await chatWithDocument(\n    {\n      sourceId,\n      message,\n      conversationHistory,\n    },\n    env\n  );\n\n  // Update conversation history\n  conversationHistory.push(\n    { role: 'user', content: message },\n    { role: 'assistant', content: response.response }\n  );\n\n  // Store updated history (expire after 24 hours)\n  await env.CACHE.put(historyKey, JSON.stringify(conversationHistory), {\n    expirationTtl: 86400,\n  });\n\n  return response;\n}\n\n/**\n * Generate follow-up questions based on conversation\n */\nexport async function generateFollowUpQuestions(\n  conversationHistory: Message[],\n  env: Env\n): Promise<string[]> {\n  const systemPrompt = `Based on the conversation, generate 3 insightful follow-up questions\nthat would help the user learn more about the topic. Return only a JSON array of strings.`;\n\n  const conversationText = conversationHistory\n    .map((m) => `${m.role}: ${m.content}`)\n    .join('\\n');\n\n  const response = await generateWithHistory(\n    [\n      { role: 'system', content: systemPrompt },\n      { role: 'user', content: conversationText },\n    ],\n    env,\n    { temperature: 0.8 }\n  );\n\n  // Parse JSON response\n  const jsonMatch = response.match(/\\[[\\s\\S]*\\]/);\n  if (!jsonMatch) {\n    return [];\n  }\n\n  return JSON.parse(jsonMatch[0]) as string[];\n}\n\n/**\n * Analyze user's understanding level based on questions\n */\nexport async function analyzeUnderstandingLevel(\n  conversationHistory: Message[],\n  env: Env\n): Promise<{\n  level: 'beginner' | 'intermediate' | 'advanced';\n  knowledgeGaps: string[];\n  recommendations: string[];\n}> {\n  const systemPrompt = `Analyze this conversation to determine the user's understanding level.\nRespond with JSON:\n{\n  \"level\": \"beginner|intermediate|advanced\",\n  \"knowledgeGaps\": [\"gap1\", \"gap2\"],\n  \"recommendations\": [\"recommendation1\", \"recommendation2\"]\n}`;\n\n  const conversationText = conversationHistory\n    .map((m) => `${m.role}: ${m.content}`)\n    .join('\\n');\n\n  const response = await generateWithHistory(\n    [\n      { role: 'system', content: systemPrompt },\n      { role: 'user', content: conversationText },\n    ],\n    env,\n    { temperature: 0.5 }\n  );\n\n  const jsonMatch = response.match(/\\{[\\s\\S]*\\}/);\n  if (!jsonMatch) {\n    throw new Error('Failed to analyze understanding level');\n  }\n\n  return JSON.parse(jsonMatch[0]);\n}\n", "import type {\n  Env,\n  StudyGuideRequest,\n  StudyGuideResponse,\n  KeyTopic,\n  TimelineEvent,\n  VocabularyTerm,\n} from '../types/env';\nimport { searchRelevantChunks } from './embeddings';\nimport { generateJSON, generateText } from './llm';\n\n/**\n * Generate comprehensive study guide from source material\n * Inspired by NotebookLM's study guide feature\n */\nexport async function generateStudyGuide(\n  request: StudyGuideRequest,\n  env: Env\n): Promise<StudyGuideResponse> {\n  const { sourceId, focusAreas = [], difficulty = 'intermediate' } = request;\n\n  // 1. Get all relevant content chunks\n  const allChunks = await searchRelevantChunks('main topics and key concepts', sourceId, 20, env);\n\n  const fullContent = allChunks.map((c) => c.content).join('\\n\\n');\n\n  // 2. Generate overview\n  const overview = await generateOverview(fullContent, difficulty, env);\n\n  // 3. Extract key topics with hierarchy\n  const keyTopics = await extractKeyTopics(fullContent, focusAreas, env);\n\n  // 4. Generate timeline if content is chronological/historical\n  const timeline = await generateTimeline(fullContent, env);\n\n  // 5. Extract important vocabulary\n  const vocabulary = await extractVocabulary(fullContent, env);\n\n  // 6. Generate practice questions\n  const practiceQuestions = await generatePracticeQuestions(fullContent, difficulty, env);\n\n  // 7. Generate title\n  const title = await generateTitle(fullContent, env);\n\n  return {\n    title,\n    overview,\n    keyTopics,\n    timeline,\n    vocabulary,\n    practiceQuestions,\n  };\n}\n\n/**\n * Generate overview summary\n */\nasync function generateOverview(\n  content: string,\n  difficulty: string,\n  env: Env\n): Promise<string> {\n  const systemPrompt = `Create a comprehensive overview of this content suitable for ${difficulty} level learners.\nThe overview should:\n- Summarize the main themes and ideas\n- Explain the significance and context\n- Be 200-300 words\n- Use clear, accessible language`;\n\n  return generateText(content, systemPrompt, env, {\n    temperature: 0.6,\n    maxTokens: 500,\n  });\n}\n\n/**\n * Extract key topics with hierarchical structure\n */\nasync function extractKeyTopics(\n  content: string,\n  focusAreas: string[],\n  env: Env\n): Promise<KeyTopic[]> {\n  const systemPrompt = `Identify and organize the key topics from this content.\n${focusAreas.length > 0 ? `Focus particularly on: ${focusAreas.join(', ')}` : ''}\n\nFor each topic, provide:\n- Main topic name\n- Concise summary (2-3 sentences)\n- List of subtopics\n- Importance score (1-10)\n\nReturn as JSON array following this schema:\n[{\n  \"topic\": \"Main Topic Name\",\n  \"summary\": \"Brief explanation...\",\n  \"subtopics\": [\"subtopic1\", \"subtopic2\"],\n  \"importance\": 8\n}]`;\n\n  const prompt = `Content to analyze:\\n\\n${content.substring(0, 8000)}`; // Limit content length\n\n  const schema = `[{\"topic\": \"...\", \"summary\": \"...\", \"subtopics\": [...], \"importance\": 1-10}]`;\n\n  const topics = await generateJSON<KeyTopic[]>(prompt, systemPrompt, schema, env);\n\n  // Sort by importance\n  return topics.sort((a, b) => b.importance - a.importance);\n}\n\n/**\n * Generate chronological timeline\n */\nasync function generateTimeline(content: string, env: Env): Promise<TimelineEvent[] | undefined> {\n  const systemPrompt = `Analyze if this content contains chronological/historical events.\nIf yes, create a timeline of key events.\nIf no, return empty array.\n\nFor each event, provide:\n- Date (if mentioned, otherwise null)\n- Event name\n- Brief description\n- Why it's significant\n\nReturn as JSON array:\n[{\n  \"date\": \"1969-07-20\" or null,\n  \"event\": \"Event name\",\n  \"description\": \"What happened...\",\n  \"significance\": \"Why it matters...\"\n}]`;\n\n  const prompt = `Content to analyze for timeline:\\n\\n${content.substring(0, 6000)}`;\n\n  try {\n    const timeline = await generateJSON<TimelineEvent[]>(\n      prompt,\n      systemPrompt,\n      '[{\"date\": \"...\", \"event\": \"...\", \"description\": \"...\", \"significance\": \"...\"}]',\n      env\n    );\n\n    // Only return timeline if it has events\n    return timeline.length > 0 ? timeline : undefined;\n  } catch {\n    return undefined;\n  }\n}\n\n/**\n * Extract vocabulary terms with definitions\n */\nasync function extractVocabulary(content: string, env: Env): Promise<VocabularyTerm[]> {\n  const systemPrompt = `Identify important vocabulary terms and concepts from this content.\nFocus on:\n- Technical terms\n- Specialized vocabulary\n- Key concepts\n- Terms that might be unfamiliar to learners\n\nFor each term, provide:\n- The term itself\n- Clear, concise definition\n- Context/example from the source material\n\nReturn top 10-15 most important terms as JSON:\n[{\n  \"term\": \"Term name\",\n  \"definition\": \"Clear definition...\",\n  \"context\": \"How it's used in the content...\"\n}]`;\n\n  const prompt = `Content to analyze:\\n\\n${content.substring(0, 6000)}`;\n\n  const schema = `[{\"term\": \"...\", \"definition\": \"...\", \"context\": \"...\"}]`;\n\n  return generateJSON<VocabularyTerm[]>(prompt, systemPrompt, schema, env);\n}\n\n/**\n * Generate practice questions\n */\nasync function generatePracticeQuestions(\n  content: string,\n  difficulty: string,\n  env: Env\n): Promise<string[]> {\n  const systemPrompt = `Generate 8-10 practice questions based on this content.\nDifficulty level: ${difficulty}\n\nQuestions should:\n- Cover different aspects of the material\n- Vary in type (recall, analysis, application)\n- Be clear and specific\n- Encourage deep thinking\n\nReturn only a JSON array of question strings (no answers).`;\n\n  const prompt = `Content for questions:\\n\\n${content.substring(0, 6000)}`;\n\n  const schema = `[\"Question 1?\", \"Question 2?\", ...]`;\n\n  return generateJSON<string[]>(prompt, systemPrompt, schema, env);\n}\n\n/**\n * Generate appropriate title for study guide\n */\nasync function generateTitle(content: string, env: Env): Promise<string> {\n  const systemPrompt = `Generate a clear, descriptive title for a study guide based on this content.\nThe title should be:\n- 5-10 words\n- Descriptive of the main topic\n- Professional and academic in tone\n\nReturn only the title text, nothing else.`;\n\n  const prompt = content.substring(0, 1000);\n\n  return generateText(prompt, systemPrompt, env, {\n    temperature: 0.5,\n    maxTokens: 50,\n  });\n}\n\n/**\n * Generate study plan based on content\n */\nexport async function generateStudyPlan(\n  studyGuide: StudyGuideResponse,\n  targetDays: number,\n  env: Env\n): Promise<\n  Array<{\n    day: number;\n    topics: string[];\n    tasks: string[];\n    estimatedHours: number;\n  }>\n> {\n  const systemPrompt = `Create a ${targetDays}-day study plan based on this study guide.\nDistribute topics logically across days, starting with fundamentals.\n\nReturn JSON array:\n[{\n  \"day\": 1,\n  \"topics\": [\"Topic to cover\"],\n  \"tasks\": [\"Specific task 1\", \"Specific task 2\"],\n  \"estimatedHours\": 2\n}]`;\n\n  const prompt = `Study Guide Summary:\nTitle: ${studyGuide.title}\nKey Topics: ${studyGuide.keyTopics.map((t) => t.topic).join(', ')}\nNumber of vocabulary terms: ${studyGuide.vocabulary.length}\nPractice questions: ${studyGuide.practiceQuestions.length}`;\n\n  const schema = `[{\"day\": 1, \"topics\": [...], \"tasks\": [...], \"estimatedHours\": 1}]`;\n\n  return generateJSON(prompt, systemPrompt, schema, env);\n}\n", "import type {\n  Env,\n  FlashcardGenerationRequest,\n  FlashcardGenerationResponse,\n  GeneratedFlashcard,\n} from '../types/env';\nimport { searchRelevantChunks } from './embeddings';\nimport { generateJSON, generateText } from './llm';\n\n/**\n * Advanced flashcard generation using Llama 3.3\n * Creates high-quality, contextual flashcards with difficulty levels\n */\nexport async function generateFlashcards(\n  request: FlashcardGenerationRequest,\n  env: Env\n): Promise<FlashcardGenerationResponse> {\n  const { sourceId, count = 20, difficulty = 'medium', topics = [] } = request;\n\n  // 1. Get relevant content\n  const searchQuery =\n    topics.length > 0\n      ? `key concepts and facts about ${topics.join(', ')}`\n      : 'important concepts, facts, and definitions';\n\n  const chunks = await searchRelevantChunks(searchQuery, sourceId, 15, env);\n  const content = chunks.map((c) => c.content).join('\\n\\n');\n\n  // 2. Generate flashcards in batches\n  const batchSize = 10;\n  const allCards: GeneratedFlashcard[] = [];\n\n  for (let i = 0; i < count; i += batchSize) {\n    const batchCount = Math.min(batchSize, count - i);\n    const cards = await generateFlashcardBatch(content, batchCount, difficulty, topics, env);\n    allCards.push(...cards);\n  }\n\n  // 3. Deduplicate and rank by quality\n  const uniqueCards = deduplicateFlashcards(allCards);\n  const rankedCards = await rankFlashcardsByQuality(uniqueCards, env);\n\n  // 4. Get source metadata\n  const sourceTitle = await getSourceTitle(sourceId, content, env);\n\n  return {\n    cards: rankedCards.slice(0, count),\n    metadata: {\n      totalGenerated: rankedCards.length,\n      difficulty,\n      sourceTitle,\n    },\n  };\n}\n\n/**\n * Generate a batch of flashcards\n */\nasync function generateFlashcardBatch(\n  content: string,\n  count: number,\n  difficulty: string,\n  topics: string[],\n  env: Env\n): Promise<GeneratedFlashcard[]> {\n  const systemPrompt = `You are an expert educator creating high-quality flashcards.\n\nCreate exactly ${count} flashcards with these criteria:\n- Difficulty: ${difficulty}\n${topics.length > 0 ? `- Focus topics: ${topics.join(', ')}` : ''}\n- Each card should test one specific concept\n- Questions should be clear and unambiguous\n- Answers should be concise but complete\n- Include helpful hints when appropriate\n- Vary question types (definition, application, comparison, etc.)\n\nReturn JSON array:\n[{\n  \"front\": \"Question or prompt (clear and specific)\",\n  \"back\": \"Answer (concise and accurate)\",\n  \"hint\": \"Optional hint (use null if not needed)\",\n  \"difficulty\": 1-10 (1=easiest, 10=hardest),\n  \"topic\": \"Specific topic this card covers\",\n  \"sourceReference\": \"Quote or reference from source material\"\n}]`;\n\n  const prompt = `Source material:\\n\\n${content.substring(0, 6000)}`;\n\n  const schema = `[{\n    \"front\": \"...\",\n    \"back\": \"...\",\n    \"hint\": \"...\" or null,\n    \"difficulty\": 1-10,\n    \"topic\": \"...\",\n    \"sourceReference\": \"...\"\n  }]`;\n\n  return generateJSON<GeneratedFlashcard[]>(prompt, systemPrompt, schema, env);\n}\n\n/**\n * Deduplicate flashcards based on semantic similarity\n */\nfunction deduplicateFlashcards(cards: GeneratedFlashcard[]): GeneratedFlashcard[] {\n  const unique: GeneratedFlashcard[] = [];\n\n  for (const card of cards) {\n    // Simple deduplication based on front text similarity\n    const isDuplicate = unique.some((existing) => {\n      const similarity = calculateTextSimilarity(card.front, existing.front);\n      return similarity > 0.8; // 80% similar = duplicate\n    });\n\n    if (!isDuplicate) {\n      unique.push(card);\n    }\n  }\n\n  return unique;\n}\n\n/**\n * Calculate simple text similarity (Jaccard coefficient)\n */\nfunction calculateTextSimilarity(text1: string, text2: string): number {\n  const words1 = new Set(text1.toLowerCase().split(/\\s+/));\n  const words2 = new Set(text2.toLowerCase().split(/\\s+/));\n\n  const intersection = new Set([...words1].filter((w) => words2.has(w)));\n  const union = new Set([...words1, ...words2]);\n\n  return intersection.size / union.size;\n}\n\n/**\n * Rank flashcards by quality using LLM\n */\nasync function rankFlashcardsByQuality(\n  cards: GeneratedFlashcard[],\n  env: Env\n): Promise<GeneratedFlashcard[]> {\n  // For large sets, just sort by difficulty and topic diversity\n  // For small sets, could use LLM to evaluate quality\n\n  if (cards.length <= 20) {\n    // LLM-based ranking for small sets\n    const systemPrompt = `Evaluate these flashcards for quality.\nRate each card 1-10 based on:\n- Clarity of question\n- Accuracy of answer\n- Educational value\n- Appropriate difficulty\n\nReturn JSON array of scores in same order: [8, 7, 9, ...]`;\n\n    try {\n      const cardsJson = JSON.stringify(cards.map((c) => ({ front: c.front, back: c.back })));\n      const scores = await generateJSON<number[]>(\n        cardsJson,\n        systemPrompt,\n        '[1, 2, 3, ...]',\n        env\n      );\n\n      // Sort by scores\n      const scored = cards.map((card, idx) => ({\n        card,\n        score: scores[idx] || 5,\n      }));\n\n      scored.sort((a, b) => b.score - a.score);\n      return scored.map((s) => s.card);\n    } catch {\n      // Fallback to simple sorting\n      return cards;\n    }\n  }\n\n  // Simple topic diversity sorting for large sets\n  return cards;\n}\n\n/**\n * Get source title\n */\nasync function getSourceTitle(\n  sourceId: string,\n  content: string,\n  env: Env\n): Promise<string> {\n  // Try to infer title from content\n  const systemPrompt = `Based on this content, generate a short title (5-8 words) that describes what this is about.\nReturn only the title text.`;\n\n  const prompt = content.substring(0, 500);\n\n  return generateText(prompt, systemPrompt, env, {\n    temperature: 0.5,\n    maxTokens: 30,\n  });\n}\n\n/**\n * Generate cloze deletion flashcards (fill-in-the-blank)\n */\nexport async function generateClozeCards(\n  sourceId: string,\n  count: number,\n  env: Env\n): Promise<GeneratedFlashcard[]> {\n  const chunks = await searchRelevantChunks('important facts and key information', sourceId, 10, env);\n  const content = chunks.map((c) => c.content).join('\\n\\n');\n\n  const systemPrompt = `Create ${count} cloze deletion flashcards (fill-in-the-blank).\n\nFor each card:\n- Front: Sentence with [...] replacing a key term\n- Back: The missing term/phrase\n- Hint: Context clue\n\nExample:\nFront: \"The [...] is the powerhouse of the cell.\"\nBack: \"mitochondria\"\nHint: \"Organelle responsible for energy production\"\n\nReturn JSON array:\n[{\n  \"front\": \"Sentence with [...]\",\n  \"back\": \"Missing term\",\n  \"hint\": \"Context clue\",\n  \"difficulty\": 1-10,\n  \"topic\": \"Topic name\",\n  \"sourceReference\": \"Original sentence\"\n}]`;\n\n  const prompt = `Content:\\n\\n${content.substring(0, 6000)}`;\n\n  const schema = `[{\"front\": \"...\", \"back\": \"...\", \"hint\": \"...\", \"difficulty\": 1-10, \"topic\": \"...\", \"sourceReference\": \"...\"}]`;\n\n  return generateJSON<GeneratedFlashcard[]>(prompt, systemPrompt, schema, env);\n}\n\n/**\n * Generate image occlusion cards (for diagrams)\n * Note: Requires image processing capabilities\n */\nexport async function generateImageOcclusionCards(\n  imageUrl: string,\n  description: string,\n  env: Env\n): Promise<GeneratedFlashcard[]> {\n  // This would require vision model support\n  // Placeholder for future implementation with Llama Vision or similar\n\n  const systemPrompt = `Based on this diagram description, create flashcards that would work with image occlusion.\nEach card should test one labeled part or concept from the diagram.\n\nDescription: ${description}\n\nReturn JSON array of cards.`;\n\n  return generateJSON<GeneratedFlashcard[]>(\n    description,\n    systemPrompt,\n    '[{\"front\": \"...\", \"back\": \"...\", \"hint\": \"...\", \"difficulty\": 1-10, \"topic\": \"...\", \"sourceReference\": \"...\"}]',\n    env\n  );\n}\n\n/**\n * Adapt flashcard difficulty based on user performance\n */\nexport async function adaptFlashcardDifficulty(\n  card: GeneratedFlashcard,\n  userPerformance: {\n    attempts: number;\n    successRate: number;\n    averageResponseTime: number;\n  },\n  env: Env\n): Promise<GeneratedFlashcard> {\n  const systemPrompt = `Adapt this flashcard based on user performance.\n\nCurrent card:\nFront: ${card.front}\nBack: ${card.back}\nCurrent difficulty: ${card.difficulty}\n\nUser performance:\n- Attempts: ${userPerformance.attempts}\n- Success rate: ${userPerformance.successRate}%\n- Avg response time: ${userPerformance.averageResponseTime}ms\n\nIf user is struggling (success rate < 60%), simplify the card.\nIf user is excelling (success rate > 90%, fast responses), make it more challenging.\n\nReturn adapted card as JSON with same schema.`;\n\n  const schema = `{\"front\": \"...\", \"back\": \"...\", \"hint\": \"...\", \"difficulty\": 1-10, \"topic\": \"...\", \"sourceReference\": \"...\"}`;\n\n  return generateJSON<GeneratedFlashcard>(JSON.stringify(card), systemPrompt, schema, env);\n}\n", "import type {\n  Env,\n  AudioOverviewRequest,\n  AudioOverviewResponse,\n  Speaker,\n  SpeakerSegment,\n} from '../types/env';\nimport { searchRelevantChunks } from './embeddings';\nimport { generateJSON, generateText } from './llm';\n\n/**\n * Generate NotebookLM-style audio overview\n * Creates podcast-like conversations discussing the content\n */\nexport async function generateAudioOverview(\n  request: AudioOverviewRequest,\n  env: Env\n): Promise<AudioOverviewResponse> {\n  const { sourceId, style = 'conversational', duration = 300 } = request; // 5 min default\n\n  // 1. Get comprehensive content overview\n  const chunks = await searchRelevantChunks('main topics, key concepts, and interesting points', sourceId, 25, env);\n  const content = chunks.map((c) => c.content).join('\\n\\n');\n\n  // 2. Generate dialogue script\n  const script = await generateDialogueScript(content, style, duration, env);\n\n  // 3. Generate audio from script using TTS\n  const audioResult = await synthesizeSpeech(script, env);\n\n  return {\n    audioUrl: audioResult.audioUrl,\n    transcript: script.fullTranscript,\n    speakers: script.speakers,\n    duration: audioResult.duration,\n  };\n}\n\n/**\n * Generate dialogue script for audio overview\n */\nasync function generateDialogueScript(\n  content: string,\n  style: string,\n  targetDuration: number,\n  env: Env\n): Promise<{\n  speakers: Speaker[];\n  fullTranscript: string;\n}> {\n  const wordsPerMinute = 150; // Average speaking pace\n  const targetWords = (targetDuration / 60) * wordsPerMinute;\n\n  let systemPrompt = '';\n\n  switch (style) {\n    case 'conversational':\n      systemPrompt = `Create an engaging podcast-style conversation between two hosts discussing this content.\n\nHosts:\n- Alex (curious learner, asks questions)\n- Jamie (knowledgeable guide, explains concepts)\n\nGuidelines:\n- Natural, conversational tone\n- Use \"we\", \"you know\", \"actually\" naturally\n- Ask clarifying questions\n- Make connections to real-world examples\n- Show enthusiasm for interesting points\n- Target approximately ${Math.floor(targetWords)} words\n- Break complex ideas into digestible explanations\n- Use analogies and metaphors\n\nFormat each line as:\nSPEAKER: dialogue text`;\n      break;\n\n    case 'lecture':\n      systemPrompt = `Create an educational lecture presentation on this content.\n\nSpeaker: Professor Morgan (expert educator)\n\nGuidelines:\n- Structured and organized\n- Clear explanations with examples\n- Build from fundamentals to complex ideas\n- Emphasize key takeaways\n- Target approximately ${Math.floor(targetWords)} words\n- Professional but accessible tone\n\nFormat each line as:\nPROFESSOR: lecture text`;\n      break;\n\n    case 'debate':\n      systemPrompt = `Create a friendly debate between two perspectives on this content.\n\nDebaters:\n- Riley (Perspective A)\n- Sam (Perspective B)\n\nGuidelines:\n- Present different viewpoints or interpretations\n- Support arguments with evidence from material\n- Respectful disagreement\n- Find common ground\n- Target approximately ${Math.floor(targetWords)} words\n\nFormat each line as:\nSPEAKER: dialogue text`;\n      break;\n  }\n\n  const prompt = `Content to discuss:\\n\\n${content.substring(0, 10000)}`;\n\n  const dialogue = await generateText(prompt, systemPrompt, env, {\n    temperature: 0.9, // Higher temperature for more natural conversation\n    maxTokens: Math.ceil(targetWords * 1.5),\n  });\n\n  // Parse dialogue into structured format\n  const lines = dialogue.split('\\n').filter((line) => line.trim());\n  const segments: Map<string, SpeakerSegment[]> = new Map();\n\n  let timestamp = 0;\n  for (const line of lines) {\n    const match = line.match(/^([A-Z]+):\\s*(.+)$/);\n    if (!match) continue;\n\n    const [, speaker, text] = match;\n    const words = text.split(/\\s+/).length;\n    const segmentDuration = (words / wordsPerMinute) * 60; // seconds\n\n    if (!segments.has(speaker)) {\n      segments.set(speaker, []);\n    }\n\n    segments.get(speaker)!.push({\n      timestamp,\n      text: text.trim(),\n    });\n\n    timestamp += segmentDuration;\n  }\n\n  // Create speakers array\n  const speakers: Speaker[] = Array.from(segments.entries()).map(([name, segs], idx) => ({\n    name,\n    voice: getVoiceForSpeaker(name, idx),\n    segments: segs,\n  }));\n\n  return {\n    speakers,\n    fullTranscript: dialogue,\n  };\n}\n\n/**\n * Synthesize speech from dialogue script\n */\nasync function synthesizeSpeech(\n  script: { speakers: Speaker[]; fullTranscript: string },\n  env: Env\n): Promise<{ audioUrl: string; duration: number }> {\n  // Merge all segments in chronological order\n  const allSegments: Array<{\n    timestamp: number;\n    text: string;\n    voice: string;\n  }> = [];\n\n  for (const speaker of script.speakers) {\n    for (const segment of speaker.segments) {\n      allSegments.push({\n        timestamp: segment.timestamp,\n        text: segment.text,\n        voice: speaker.voice,\n      });\n    }\n  }\n\n  allSegments.sort((a, b) => a.timestamp - b.timestamp);\n\n  // Generate audio for each segment\n  const audioChunks: ArrayBuffer[] = [];\n  let totalDuration = 0;\n\n  for (const segment of allSegments) {\n    try {\n      // Use Cloudflare Workers AI TTS\n      // Note: As of Dec 2024, Workers AI supports text-to-speech\n      const ttsResponse = await env.AI.run('@cf/meta/m2m100-1.2b', {\n        text: segment.text,\n        source_lang: 'en',\n        target_lang: 'en',\n      });\n\n      // This is a placeholder - actual TTS model selection depends on availability\n      // You might need to use external TTS APIs like:\n      // - ElevenLabs (high quality, paid)\n      // - Google Cloud TTS\n      // - Azure TTS\n      // - Coqui TTS (open source)\n\n      // For now, we'll create a reference to external TTS\n      const audioBuffer = await synthesizeWithExternalTTS(segment.text, segment.voice, env);\n      audioChunks.push(audioBuffer);\n\n      // Estimate duration (rough calculation)\n      const words = segment.text.split(/\\s+/).length;\n      totalDuration += (words / 150) * 60; // 150 WPM average\n    } catch (error) {\n      console.error('TTS error:', error);\n      // Continue with other segments\n    }\n  }\n\n  // Combine audio chunks\n  const combinedAudio = combineAudioBuffers(audioChunks);\n\n  // Upload to R2 (if available)\n  let audioUrl = '';\n\n  if (env.AUDIO_BUCKET) {\n    const audioKey = `audio-overviews/${crypto.randomUUID()}.mp3`;\n    await env.AUDIO_BUCKET.put(audioKey, combinedAudio, {\n      httpMetadata: {\n        contentType: 'audio/mpeg',\n      },\n    });\n    audioUrl = `https://audio.edufeed.com/${audioKey}`;\n  } else {\n    // R2 not enabled - return base64 data URL for now\n    const base64Audio = btoa(String.fromCharCode(...new Uint8Array(combinedAudio)));\n    audioUrl = `data:audio/mpeg;base64,${base64Audio}`;\n  }\n\n  return {\n    audioUrl,\n    duration: totalDuration,\n  };\n}\n\n/**\n * External TTS synthesis (placeholder for actual implementation)\n */\nasync function synthesizeWithExternalTTS(\n  text: string,\n  voice: string,\n  env: Env\n): Promise<ArrayBuffer> {\n  // This would integrate with external TTS service\n  // For example, ElevenLabs API:\n  /*\n  const response = await fetch('https://api.elevenlabs.io/v1/text-to-speech/voice_id', {\n    method: 'POST',\n    headers: {\n      'Accept': 'audio/mpeg',\n      'Content-Type': 'application/json',\n      'xi-api-key': env.ELEVENLABS_API_KEY,\n    },\n    body: JSON.stringify({\n      text,\n      model_id: 'eleven_monolingual_v1',\n      voice_settings: {\n        stability: 0.5,\n        similarity_boost: 0.5,\n      },\n    }),\n  });\n\n  return await response.arrayBuffer();\n  */\n\n  // Placeholder: return empty buffer\n  return new ArrayBuffer(0);\n}\n\n/**\n * Combine multiple audio buffers into one\n */\nfunction combineAudioBuffers(buffers: ArrayBuffer[]): ArrayBuffer {\n  // Calculate total length\n  const totalLength = buffers.reduce((sum, buf) => sum + buf.byteLength, 0);\n\n  // Create combined buffer\n  const combined = new Uint8Array(totalLength);\n  let offset = 0;\n\n  for (const buffer of buffers) {\n    combined.set(new Uint8Array(buffer), offset);\n    offset += buffer.byteLength;\n  }\n\n  return combined.buffer;\n}\n\n/**\n * Get appropriate voice for speaker\n */\nfunction getVoiceForSpeaker(name: string, index: number): string {\n  // Map speaker names to voice IDs\n  // These would be actual voice IDs from your TTS provider\n\n  const voiceMap: Record<string, string> = {\n    ALEX: 'voice_id_casual_curious',\n    JAMIE: 'voice_id_knowledgeable_friendly',\n    PROFESSOR: 'voice_id_authoritative_clear',\n    RILEY: 'voice_id_thoughtful_articulate',\n    SAM: 'voice_id_analytical_engaging',\n  };\n\n  return voiceMap[name] || `voice_${index}`;\n}\n\n/**\n * Generate chapter markers for audio\n */\nexport async function generateAudioChapters(\n  transcript: string,\n  env: Env\n): Promise<Array<{ time: number; title: string }>> {\n  const systemPrompt = `Analyze this audio transcript and create chapter markers.\nIdentify natural topic transitions and create descriptive chapter titles.\n\nReturn JSON array:\n[{\n  \"time\": 0,\n  \"title\": \"Introduction to Topic\"\n}, ...]\n\nTime should be in seconds, estimated from transcript flow.`;\n\n  const schema = `[{\"time\": 0, \"title\": \"...\"}]`;\n\n  return generateJSON(transcript, systemPrompt, schema, env);\n}\n\n/**\n * Generate show notes / summary for audio\n */\nexport async function generateShowNotes(\n  transcript: string,\n  env: Env\n): Promise<{\n  summary: string;\n  keyPoints: string[];\n  resources: string[];\n}> {\n  const systemPrompt = `Create show notes for this audio overview.\nInclude:\n- Brief summary (2-3 sentences)\n- Key points discussed (bullet points)\n- Resources mentioned or recommended\n\nReturn as JSON.`;\n\n  const schema = `{\n    \"summary\": \"...\",\n    \"keyPoints\": [\"point 1\", \"point 2\"],\n    \"resources\": [\"resource 1\", \"resource 2\"]\n  }`;\n\n  return generateJSON(transcript, systemPrompt, schema, env);\n}\n", "import type { Env } from './types/env';\nimport { chatWithDocument, continueChatConversation } from './lib/chat';\nimport { generateStudyGuide, generateStudyPlan } from './lib/study-guide';\nimport { generateFlashcards, generateClozeCards } from './lib/flashcards';\nimport { generateAudioOverview } from './lib/audio-overview';\nimport { storeDocumentEmbeddings, deleteSourceEmbeddings } from './lib/embeddings';\nimport { generateDirectSummary, generateDirectFlashcards, generateDirectTable } from './lib/direct-content';\n\n/**\n * Main Cloudflare Workers entry point\n * Handles all AI generation endpoints for EduFeed\n */\nexport default {\n  async fetch(request: Request, env: Env): Promise<Response> {\n    // CORS headers\n    const corsHeaders = {\n      'Access-Control-Allow-Origin': '*',\n      'Access-Control-Allow-Methods': 'GET, POST, PUT, DELETE, OPTIONS',\n      'Access-Control-Allow-Headers': 'Content-Type, Authorization',\n    };\n\n    // Handle CORS preflight\n    if (request.method === 'OPTIONS') {\n      return new Response(null, { headers: corsHeaders });\n    }\n\n    try {\n      const url = new URL(request.url);\n      const path = url.pathname;\n\n      // Route handling\n      switch (true) {\n        // Health check\n        case path === '/health':\n          return jsonResponse({ status: 'ok', timestamp: Date.now() }, 200, corsHeaders);\n\n        // Embeddings endpoints\n        case path === '/api/embeddings/store' && request.method === 'POST':\n          return handleStoreEmbeddings(request, env, corsHeaders);\n\n        case path === '/api/embeddings/delete' && request.method === 'DELETE':\n          return handleDeleteEmbeddings(request, env, corsHeaders);\n\n        // Chat endpoints\n        case path === '/api/chat' && request.method === 'POST':\n          return handleChat(request, env, corsHeaders);\n\n        case path === '/api/chat/continue' && request.method === 'POST':\n          return handleContinueChat(request, env, corsHeaders);\n\n        // Study guide endpoints\n        case path === '/api/study-guide/generate' && request.method === 'POST':\n          return handleGenerateStudyGuide(request, env, corsHeaders);\n\n        case path === '/api/study-guide/plan' && request.method === 'POST':\n          return handleGenerateStudyPlan(request, env, corsHeaders);\n\n        // Flashcard endpoints\n        case path === '/api/flashcards/generate' && request.method === 'POST':\n          return handleGenerateFlashcards(request, env, corsHeaders);\n\n        case path === '/api/flashcards/generate-cloze' && request.method === 'POST':\n          return handleGenerateClozeCards(request, env, corsHeaders);\n\n        // Audio overview endpoints\n        case path === '/api/audio-overview/generate' && request.method === 'POST':\n          return handleGenerateAudioOverview(request, env, corsHeaders);\n\n        default:\n          return jsonResponse({ error: 'Not found' }, 404, corsHeaders);\n      }\n    } catch (error) {\n      console.error('Error handling request:', error);\n      return jsonResponse(\n        {\n          error: 'Internal server error',\n          message: error instanceof Error ? error.message : 'Unknown error',\n        },\n        500,\n        corsHeaders\n      );\n    }\n  },\n};\n\n// ==================== Handler Functions ====================\n\n/**\n * Store document embeddings\n */\nasync function handleStoreEmbeddings(\n  request: Request,\n  env: Env,\n  corsHeaders: Record<string, string>\n): Promise<Response> {\n  const { sourceId, content, metadata } = await request.json();\n\n  if (!sourceId || !content) {\n    return jsonResponse({ error: 'Missing required fields' }, 400, corsHeaders);\n  }\n\n  await storeDocumentEmbeddings(sourceId, content, metadata, env);\n\n  return jsonResponse(\n    { success: true, message: 'Embeddings stored successfully' },\n    200,\n    corsHeaders\n  );\n}\n\n/**\n * Delete document embeddings\n */\nasync function handleDeleteEmbeddings(\n  request: Request,\n  env: Env,\n  corsHeaders: Record<string, string>\n): Promise<Response> {\n  const { sourceId } = await request.json();\n\n  if (!sourceId) {\n    return jsonResponse({ error: 'Missing sourceId' }, 400, corsHeaders);\n  }\n\n  await deleteSourceEmbeddings(sourceId, env);\n\n  return jsonResponse(\n    { success: true, message: 'Embeddings deleted successfully' },\n    200,\n    corsHeaders\n  );\n}\n\n/**\n * Handle chat request\n */\nasync function handleChat(\n  request: Request,\n  env: Env,\n  corsHeaders: Record<string, string>\n): Promise<Response> {\n  const chatRequest = await request.json();\n\n  if (!chatRequest.sourceId || !chatRequest.message) {\n    return jsonResponse({ error: 'Missing required fields' }, 400, corsHeaders);\n  }\n\n  const response = await chatWithDocument(chatRequest, env);\n\n  return jsonResponse(response, 200, corsHeaders);\n}\n\n/**\n * Handle continue chat\n */\nasync function handleContinueChat(\n  request: Request,\n  env: Env,\n  corsHeaders: Record<string, string>\n): Promise<Response> {\n  const { conversationId, message } = await request.json();\n\n  if (!conversationId || !message) {\n    return jsonResponse({ error: 'Missing required fields' }, 400, corsHeaders);\n  }\n\n  const response = await continueChatConversation(conversationId, message, env);\n\n  return jsonResponse(response, 200, corsHeaders);\n}\n\n/**\n * Handle study guide generation\n */\nasync function handleGenerateStudyGuide(\n  request: Request,\n  env: Env,\n  corsHeaders: Record<string, string>\n): Promise<Response> {\n  const studyGuideRequest = await request.json();\n\n  if (!studyGuideRequest.sourceId) {\n    return jsonResponse({ error: 'Missing sourceId' }, 400, corsHeaders);\n  }\n\n  const studyGuide = await generateStudyGuide(studyGuideRequest, env);\n\n  return jsonResponse(studyGuide, 200, corsHeaders);\n}\n\n/**\n * Handle study plan generation\n */\nasync function handleGenerateStudyPlan(\n  request: Request,\n  env: Env,\n  corsHeaders: Record<string, string>\n): Promise<Response> {\n  const { studyGuide, targetDays } = await request.json();\n\n  if (!studyGuide || !targetDays) {\n    return jsonResponse({ error: 'Missing required fields' }, 400, corsHeaders);\n  }\n\n  const plan = await generateStudyPlan(studyGuide, targetDays, env);\n\n  return jsonResponse(plan, 200, corsHeaders);\n}\n\n/**\n * Handle flashcard generation\n */\nasync function handleGenerateFlashcards(\n  request: Request,\n  env: Env,\n  corsHeaders: Record<string, string>\n): Promise<Response> {\n  const flashcardRequest = await request.json();\n\n  if (!flashcardRequest.sourceId) {\n    return jsonResponse({ error: 'Missing sourceId' }, 400, corsHeaders);\n  }\n\n  const flashcards = await generateFlashcards(flashcardRequest, env);\n\n  return jsonResponse(flashcards, 200, corsHeaders);\n}\n\n/**\n * Handle cloze card generation\n */\nasync function handleGenerateClozeCards(\n  request: Request,\n  env: Env,\n  corsHeaders: Record<string, string>\n): Promise<Response> {\n  const { sourceId, count } = await request.json();\n\n  if (!sourceId) {\n    return jsonResponse({ error: 'Missing sourceId' }, 400, corsHeaders);\n  }\n\n  const cards = await generateClozeCards(sourceId, count || 10, env);\n\n  return jsonResponse({ cards }, 200, corsHeaders);\n}\n\n/**\n * Handle audio overview generation\n */\nasync function handleGenerateAudioOverview(\n  request: Request,\n  env: Env,\n  corsHeaders: Record<string, string>\n): Promise<Response> {\n  const audioRequest = await request.json();\n\n  if (!audioRequest.sourceId) {\n    return jsonResponse({ error: 'Missing sourceId' }, 400, corsHeaders);\n  }\n\n  const audioOverview = await generateAudioOverview(audioRequest, env);\n\n  return jsonResponse(audioOverview, 200, corsHeaders);\n}\n\n// ==================== Utility Functions ====================\n\n/**\n * Create JSON response with CORS headers\n */\nfunction jsonResponse(\n  data: unknown,\n  status: number = 200,\n  corsHeaders: Record<string, string> = {}\n): Response {\n  return new Response(JSON.stringify(data), {\n    status,\n    headers: {\n      'Content-Type': 'application/json',\n      ...corsHeaders,\n    },\n  });\n}\n", "import type { Middleware } from \"./common\";\n\nconst drainBody: Middleware = async (request, env, _ctx, middlewareCtx) => {\n\ttry {\n\t\treturn await middlewareCtx.next(request, env);\n\t} finally {\n\t\ttry {\n\t\t\tif (request.body !== null && !request.bodyUsed) {\n\t\t\t\tconst reader = request.body.getReader();\n\t\t\t\twhile (!(await reader.read()).done) {}\n\t\t\t}\n\t\t} catch (e) {\n\t\t\tconsole.error(\"Failed to drain the unused request body.\", e);\n\t\t}\n\t}\n};\n\nexport default drainBody;\n", "import type { Middleware } from \"./common\";\n\ninterface JsonError {\n\tmessage?: string;\n\tname?: string;\n\tstack?: string;\n\tcause?: JsonError;\n}\n\nfunction reduceError(e: any): JsonError {\n\treturn {\n\t\tname: e?.name,\n\t\tmessage: e?.message ?? String(e),\n\t\tstack: e?.stack,\n\t\tcause: e?.cause === undefined ? undefined : reduceError(e.cause),\n\t};\n}\n\n// See comment in `bundle.ts` for details on why this is needed\nconst jsonError: Middleware = async (request, env, _ctx, middlewareCtx) => {\n\ttry {\n\t\treturn await middlewareCtx.next(request, env);\n\t} catch (e: any) {\n\t\tconst error = reduceError(e);\n\t\treturn Response.json(error, {\n\t\t\tstatus: 500,\n\t\t\theaders: { \"MF-Experimental-Error-Stack\": \"true\" },\n\t\t});\n\t}\n};\n\nexport default jsonError;\n", "\t\t\t\timport worker, * as OTHER_EXPORTS from \"/Users/annaabyzova/Projects/Website feed/workers/index.ts\";\n\t\t\t\timport * as __MIDDLEWARE_0__ from \"/Users/annaabyzova/Projects/Website feed/node_modules/wrangler/templates/middleware/middleware-ensure-req-body-drained.ts\";\nimport * as __MIDDLEWARE_1__ from \"/Users/annaabyzova/Projects/Website feed/node_modules/wrangler/templates/middleware/middleware-miniflare3-json-error.ts\";\n\n\t\t\t\texport * from \"/Users/annaabyzova/Projects/Website feed/workers/index.ts\";\n\t\t\t\tconst MIDDLEWARE_TEST_INJECT = \"__INJECT_FOR_TESTING_WRANGLER_MIDDLEWARE__\";\n\t\t\t\texport const __INTERNAL_WRANGLER_MIDDLEWARE__ = [\n\t\t\t\t\t\n\t\t\t\t\t__MIDDLEWARE_0__.default,__MIDDLEWARE_1__.default\n\t\t\t\t]\n\t\t\t\texport default worker;", "export type Awaitable<T> = T | Promise<T>;\n// TODO: allow dispatching more events?\nexport type Dispatcher = (\n\ttype: \"scheduled\",\n\tinit: { cron?: string }\n) => Awaitable<void>;\n\nexport type IncomingRequest = Request<\n\tunknown,\n\tIncomingRequestCfProperties<unknown>\n>;\n\nexport interface MiddlewareContext {\n\tdispatch: Dispatcher;\n\tnext(request: IncomingRequest, env: any): Awaitable<Response>;\n}\n\nexport type Middleware = (\n\trequest: IncomingRequest,\n\tenv: any,\n\tctx: ExecutionContext,\n\tmiddlewareCtx: MiddlewareContext\n) => Awaitable<Response>;\n\nconst __facade_middleware__: Middleware[] = [];\n\n// The register functions allow for the insertion of one or many middleware,\n// We register internal middleware first in the stack, but have no way of controlling\n// the order that addMiddleware is run in service workers so need an internal function.\nexport function __facade_register__(...args: (Middleware | Middleware[])[]) {\n\t__facade_middleware__.push(...args.flat());\n}\nexport function __facade_registerInternal__(\n\t...args: (Middleware | Middleware[])[]\n) {\n\t__facade_middleware__.unshift(...args.flat());\n}\n\nfunction __facade_invokeChain__(\n\trequest: IncomingRequest,\n\tenv: any,\n\tctx: ExecutionContext,\n\tdispatch: Dispatcher,\n\tmiddlewareChain: Middleware[]\n): Awaitable<Response> {\n\tconst [head, ...tail] = middlewareChain;\n\tconst middlewareCtx: MiddlewareContext = {\n\t\tdispatch,\n\t\tnext(newRequest, newEnv) {\n\t\t\treturn __facade_invokeChain__(newRequest, newEnv, ctx, dispatch, tail);\n\t\t},\n\t};\n\treturn head(request, env, ctx, middlewareCtx);\n}\n\nexport function __facade_invoke__(\n\trequest: IncomingRequest,\n\tenv: any,\n\tctx: ExecutionContext,\n\tdispatch: Dispatcher,\n\tfinalMiddleware: Middleware\n): Awaitable<Response> {\n\treturn __facade_invokeChain__(request, env, ctx, dispatch, [\n\t\t...__facade_middleware__,\n\t\tfinalMiddleware,\n\t]);\n}\n", "// This loads all middlewares exposed on the middleware object and then starts\n// the invocation chain. The big idea is that we can add these to the middleware\n// export dynamically through wrangler, or we can potentially let users directly\n// add them as a sort of \"plugin\" system.\n\nimport ENTRY, { __INTERNAL_WRANGLER_MIDDLEWARE__ } from \"/Users/annaabyzova/Projects/Website feed/.wrangler/tmp/bundle-e01auW/middleware-insertion-facade.js\";\nimport { __facade_invoke__, __facade_register__, Dispatcher } from \"/Users/annaabyzova/Projects/Website feed/node_modules/wrangler/templates/middleware/common.ts\";\nimport type { WorkerEntrypointConstructor } from \"/Users/annaabyzova/Projects/Website feed/.wrangler/tmp/bundle-e01auW/middleware-insertion-facade.js\";\n\n// Preserve all the exports from the worker\nexport * from \"/Users/annaabyzova/Projects/Website feed/.wrangler/tmp/bundle-e01auW/middleware-insertion-facade.js\";\n\nclass __Facade_ScheduledController__ implements ScheduledController {\n\treadonly #noRetry: ScheduledController[\"noRetry\"];\n\n\tconstructor(\n\t\treadonly scheduledTime: number,\n\t\treadonly cron: string,\n\t\tnoRetry: ScheduledController[\"noRetry\"]\n\t) {\n\t\tthis.#noRetry = noRetry;\n\t}\n\n\tnoRetry() {\n\t\tif (!(this instanceof __Facade_ScheduledController__)) {\n\t\t\tthrow new TypeError(\"Illegal invocation\");\n\t\t}\n\t\t// Need to call native method immediately in case uncaught error thrown\n\t\tthis.#noRetry();\n\t}\n}\n\nfunction wrapExportedHandler(worker: ExportedHandler): ExportedHandler {\n\t// If we don't have any middleware defined, just return the handler as is\n\tif (\n\t\t__INTERNAL_WRANGLER_MIDDLEWARE__ === undefined ||\n\t\t__INTERNAL_WRANGLER_MIDDLEWARE__.length === 0\n\t) {\n\t\treturn worker;\n\t}\n\t// Otherwise, register all middleware once\n\tfor (const middleware of __INTERNAL_WRANGLER_MIDDLEWARE__) {\n\t\t__facade_register__(middleware);\n\t}\n\n\tconst fetchDispatcher: ExportedHandlerFetchHandler = function (\n\t\trequest,\n\t\tenv,\n\t\tctx\n\t) {\n\t\tif (worker.fetch === undefined) {\n\t\t\tthrow new Error(\"Handler does not export a fetch() function.\");\n\t\t}\n\t\treturn worker.fetch(request, env, ctx);\n\t};\n\n\treturn {\n\t\t...worker,\n\t\tfetch(request, env, ctx) {\n\t\t\tconst dispatcher: Dispatcher = function (type, init) {\n\t\t\t\tif (type === \"scheduled\" && worker.scheduled !== undefined) {\n\t\t\t\t\tconst controller = new __Facade_ScheduledController__(\n\t\t\t\t\t\tDate.now(),\n\t\t\t\t\t\tinit.cron ?? \"\",\n\t\t\t\t\t\t() => {}\n\t\t\t\t\t);\n\t\t\t\t\treturn worker.scheduled(controller, env, ctx);\n\t\t\t\t}\n\t\t\t};\n\t\t\treturn __facade_invoke__(request, env, ctx, dispatcher, fetchDispatcher);\n\t\t},\n\t};\n}\n\nfunction wrapWorkerEntrypoint(\n\tklass: WorkerEntrypointConstructor\n): WorkerEntrypointConstructor {\n\t// If we don't have any middleware defined, just return the handler as is\n\tif (\n\t\t__INTERNAL_WRANGLER_MIDDLEWARE__ === undefined ||\n\t\t__INTERNAL_WRANGLER_MIDDLEWARE__.length === 0\n\t) {\n\t\treturn klass;\n\t}\n\t// Otherwise, register all middleware once\n\tfor (const middleware of __INTERNAL_WRANGLER_MIDDLEWARE__) {\n\t\t__facade_register__(middleware);\n\t}\n\n\t// `extend`ing `klass` here so other RPC methods remain callable\n\treturn class extends klass {\n\t\t#fetchDispatcher: ExportedHandlerFetchHandler<Record<string, unknown>> = (\n\t\t\trequest,\n\t\t\tenv,\n\t\t\tctx\n\t\t) => {\n\t\t\tthis.env = env;\n\t\t\tthis.ctx = ctx;\n\t\t\tif (super.fetch === undefined) {\n\t\t\t\tthrow new Error(\"Entrypoint class does not define a fetch() function.\");\n\t\t\t}\n\t\t\treturn super.fetch(request);\n\t\t};\n\n\t\t#dispatcher: Dispatcher = (type, init) => {\n\t\t\tif (type === \"scheduled\" && super.scheduled !== undefined) {\n\t\t\t\tconst controller = new __Facade_ScheduledController__(\n\t\t\t\t\tDate.now(),\n\t\t\t\t\tinit.cron ?? \"\",\n\t\t\t\t\t() => {}\n\t\t\t\t);\n\t\t\t\treturn super.scheduled(controller);\n\t\t\t}\n\t\t};\n\n\t\tfetch(request: Request<unknown, IncomingRequestCfProperties>) {\n\t\t\treturn __facade_invoke__(\n\t\t\t\trequest,\n\t\t\t\tthis.env,\n\t\t\t\tthis.ctx,\n\t\t\t\tthis.#dispatcher,\n\t\t\t\tthis.#fetchDispatcher\n\t\t\t);\n\t\t}\n\t};\n}\n\nlet WRAPPED_ENTRY: ExportedHandler | WorkerEntrypointConstructor | undefined;\nif (typeof ENTRY === \"object\") {\n\tWRAPPED_ENTRY = wrapExportedHandler(ENTRY);\n} else if (typeof ENTRY === \"function\") {\n\tWRAPPED_ENTRY = wrapWorkerEntrypoint(ENTRY);\n}\nexport default WRAPPED_ENTRY;\n"],
  "mappings": ";;;;;AAuBO,SAAS,0BAA0B,MAAM;AAC/C,SAAO,IAAI,MAAM,WAAW,IAAI,0BAA0B;AAC3D;AAFgB;AAAA;AAIT,SAAS,eAAe,MAAM;AACpC,QAAM,KAAK,6BAAM;AAChB,UAAM,0CAA0B,IAAI;AAAA,EACrC,GAFW;AAGX,SAAO,OAAO,OAAO,IAAI,EAAE,WAAW,KAAK,CAAC;AAC7C;AALgB;;AAcT,SAAS,oBAAoB,MAAM;AACzC,SAAO,MAAM;AAAA,IACZ,YAAY;AAAA,IACZ,cAAc;AACb,YAAM,IAAI,MAAM,WAAW,IAAI,0BAA0B;AAAA,IAC1D;AAAA,EACD;AACD;AAPgB;;;ACxChB,IAAM,cAAc,WAAW,aAAa,cAAc,KAAK,IAAI;AACnE,IAAM,kBAAkB,WAAW,aAAa,MAAM,WAAW,YAAY,IAAI,KAAK,WAAW,WAAW,IAAI,MAAM,KAAK,IAAI,IAAI;AACnI,IAAM,aAAa;AAAA,EAClB,MAAM;AAAA,EACN,WAAW;AAAA,EACX,WAAW;AAAA,EACX,UAAU;AAAA,EACV,WAAW;AAAA,EACX,SAAS;AAAA,EACT,mBAAmB;AAAA,EACnB,aAAa;AAAA,EACb,WAAW;AAAA,EACX,UAAU;AAAA,EACV,UAAU;AAAA,EACV,eAAe;AAAA,IACd,WAAW;AAAA,IACX,QAAQ;AAAA,IACR,eAAe;AAAA,EAChB;AAAA,EACA,QAAQ;AAAA,EACR,SAAS;AACR,WAAO;AAAA,EACR;AACD;AAEO,IAAM,mBAAN,MAAuB;AAAA,EA1B9B,OA0B8B;AAAA;AAAA;AAAA,EAC7B,YAAY;AAAA,EACZ;AAAA,EACA,YAAY;AAAA,EACZ;AAAA,EACA;AAAA,EACA,YAAY,MAAM,SAAS;AAC1B,SAAK,OAAO;AACZ,SAAK,YAAY,SAAS,aAAa,gBAAgB;AACvD,SAAK,SAAS,SAAS;AAAA,EACxB;AAAA,EACA,IAAI,WAAW;AACd,WAAO,gBAAgB,IAAI,KAAK;AAAA,EACjC;AAAA,EACA,SAAS;AACR,WAAO;AAAA,MACN,MAAM,KAAK;AAAA,MACX,WAAW,KAAK;AAAA,MAChB,WAAW,KAAK;AAAA,MAChB,UAAU,KAAK;AAAA,MACf,QAAQ,KAAK;AAAA,IACd;AAAA,EACD;AACD;AAEO,IAAM,kBAAkB,MAAMA,yBAAwB,iBAAiB;AAAA,EAnD9E,OAmD8E;AAAA;AAAA;AAAA,EAC7E,YAAY;AAAA,EACZ,cAAc;AAEb,UAAM,GAAG,SAAS;AAAA,EACnB;AAAA,EACA,IAAI,WAAW;AACd,WAAO;AAAA,EACR;AACD;AAEO,IAAM,qBAAN,cAAiC,iBAAiB;AAAA,EA9DzD,OA8DyD;AAAA;AAAA;AAAA,EACxD,YAAY;AACb;AAEO,IAAM,4BAAN,cAAwC,iBAAiB;AAAA,EAlEhE,OAkEgE;AAAA;AAAA;AAAA,EAC/D,YAAY;AAAA,EACZ,eAAe,CAAC;AAAA,EAChB,aAAa;AAAA,EACb,eAAe;AAAA,EACf,kBAAkB;AAAA,EAClB,kBAAkB;AAAA,EAClB,oBAAoB;AAAA,EACpB,kBAAkB;AAAA,EAClB,aAAa;AAAA,EACb,gBAAgB;AAAA,EAChB,OAAO;AAAA,EACP,kBAAkB;AAAA,EAClB,cAAc;AAAA,EACd,gBAAgB;AAAA,EAChB,eAAe;AAAA,EACf,cAAc;AAAA,EACd,gBAAgB;AAAA,EAChB,wBAAwB;AAAA,EACxB,YAAY;AAAA,EACZ,eAAe;AAAA,EACf,cAAc;AAAA,EACd,iBAAiB;AAClB;AAEO,IAAM,+BAAN,MAAmC;AAAA,EA3F1C,OA2F0C;AAAA;AAAA;AAAA,EACzC,YAAY;AAAA,EACZ,aAAa;AACZ,WAAO,CAAC;AAAA,EACT;AAAA,EACA,iBAAiB,OAAO,OAAO;AAC9B,WAAO,CAAC;AAAA,EACT;AAAA,EACA,iBAAiB,MAAM;AACtB,WAAO,CAAC;AAAA,EACT;AACD;AAEO,IAAM,cAAN,MAAkB;AAAA,EAxGzB,OAwGyB;AAAA;AAAA;AAAA,EACxB,YAAY;AAAA,EACZ,aAAa;AAAA,EACb,cAAc,oBAAI,IAAI;AAAA,EACtB,WAAW,CAAC;AAAA,EACZ,4BAA4B;AAAA,EAC5B,aAAa;AAAA,EACb,SAAS;AAAA,EACT,SAAS,KAAK,UAAU;AACvB,UAAM,0BAA0B,sBAAsB;AAAA,EACvD;AAAA,EACA,IAAI,aAAa;AAChB,WAAO;AAAA,EACR;AAAA,EACA,uBAAuB;AACtB,WAAO,CAAC;AAAA,EACT;AAAA,EACA,qBAAqB;AAIpB,WAAO,IAAI,0BAA0B,EAAE;AAAA,EACxC;AAAA,EACA,6BAA6B;AAAA,EAC7B,MAAM;AAEL,QAAI,KAAK,eAAe,aAAa;AACpC,aAAO,gBAAgB;AAAA,IACxB;AACA,WAAO,KAAK,IAAI,IAAI,KAAK;AAAA,EAC1B;AAAA,EACA,WAAW,UAAU;AACpB,SAAK,WAAW,WAAW,KAAK,SAAS,OAAO,CAAC,MAAM,EAAE,SAAS,QAAQ,IAAI,KAAK,SAAS,OAAO,CAAC,MAAM,EAAE,cAAc,MAAM;AAAA,EACjI;AAAA,EACA,cAAc,aAAa;AAC1B,SAAK,WAAW,cAAc,KAAK,SAAS,OAAO,CAAC,MAAM,EAAE,SAAS,WAAW,IAAI,KAAK,SAAS,OAAO,CAAC,MAAM,EAAE,cAAc,SAAS;AAAA,EAC1I;AAAA,EACA,uBAAuB;AACtB,SAAK,WAAW,KAAK,SAAS,OAAO,CAAC,MAAM,EAAE,cAAc,cAAc,EAAE,cAAc,YAAY;AAAA,EACvG;AAAA,EACA,aAAa;AACZ,WAAO,KAAK;AAAA,EACb;AAAA,EACA,iBAAiB,MAAM,MAAM;AAC5B,WAAO,KAAK,SAAS,OAAO,CAAC,MAAM,EAAE,SAAS,SAAS,CAAC,QAAQ,EAAE,cAAc,KAAK;AAAA,EACtF;AAAA,EACA,iBAAiB,MAAM;AACtB,WAAO,KAAK,SAAS,OAAO,CAAC,MAAM,EAAE,cAAc,IAAI;AAAA,EACxD;AAAA,EACA,KAAK,MAAM,SAAS;AAEnB,UAAM,QAAQ,IAAI,gBAAgB,MAAM,OAAO;AAC/C,SAAK,SAAS,KAAK,KAAK;AACxB,WAAO;AAAA,EACR;AAAA,EACA,QAAQ,aAAa,uBAAuB,SAAS;AACpD,QAAI;AACJ,QAAI;AACJ,QAAI,OAAO,0BAA0B,UAAU;AAC9C,cAAQ,KAAK,iBAAiB,uBAAuB,MAAM,EAAE,CAAC,GAAG;AACjE,YAAM,KAAK,iBAAiB,SAAS,MAAM,EAAE,CAAC,GAAG;AAAA,IAClD,OAAO;AACN,cAAQ,OAAO,WAAW,uBAAuB,KAAK,KAAK,KAAK,IAAI;AACpE,YAAM,OAAO,WAAW,uBAAuB,GAAG,KAAK,KAAK,IAAI;AAAA,IACjE;AACA,UAAM,QAAQ,IAAI,mBAAmB,aAAa;AAAA,MACjD,WAAW;AAAA,MACX,QAAQ;AAAA,QACP;AAAA,QACA;AAAA,MACD;AAAA,IACD,CAAC;AACD,SAAK,SAAS,KAAK,KAAK;AACxB,WAAO;AAAA,EACR;AAAA,EACA,4BAA4B,SAAS;AACpC,SAAK,4BAA4B;AAAA,EAClC;AAAA,EACA,iBAAiB,MAAM,UAAU,SAAS;AACzC,UAAM,0BAA0B,8BAA8B;AAAA,EAC/D;AAAA,EACA,oBAAoB,MAAM,UAAU,SAAS;AAC5C,UAAM,0BAA0B,iCAAiC;AAAA,EAClE;AAAA,EACA,cAAc,OAAO;AACpB,UAAM,0BAA0B,2BAA2B;AAAA,EAC5D;AAAA,EACA,SAAS;AACR,WAAO;AAAA,EACR;AACD;AAEO,IAAM,sBAAN,MAA0B;AAAA,EApMjC,OAoMiC;AAAA;AAAA;AAAA,EAChC,YAAY;AAAA,EACZ,OAAO,sBAAsB,CAAC;AAAA,EAC9B,YAAY;AAAA,EACZ,YAAY,UAAU;AACrB,SAAK,YAAY;AAAA,EAClB;AAAA,EACA,cAAc;AACb,WAAO,CAAC;AAAA,EACT;AAAA,EACA,aAAa;AACZ,UAAM,0BAA0B,gCAAgC;AAAA,EACjE;AAAA,EACA,QAAQ,SAAS;AAChB,UAAM,0BAA0B,6BAA6B;AAAA,EAC9D;AAAA,EACA,KAAK,IAAI;AACR,WAAO;AAAA,EACR;AAAA,EACA,gBAAgB,IAAI,YAAY,MAAM;AACrC,WAAO,GAAG,KAAK,SAAS,GAAG,IAAI;AAAA,EAChC;AAAA,EACA,UAAU;AACT,WAAO;AAAA,EACR;AAAA,EACA,iBAAiB;AAChB,WAAO;AAAA,EACR;AAAA,EACA,cAAc;AACb,WAAO;AAAA,EACR;AACD;AAIO,IAAM,cAAc,WAAW,eAAe,sBAAsB,WAAW,cAAc,WAAW,cAAc,IAAI,YAAY;;;AC7N7I,WAAW,cAAc;AACzB,WAAW,cAAc;AACzB,WAAW,mBAAmB;AAC9B,WAAW,kBAAkB;AAC7B,WAAW,qBAAqB;AAChC,WAAW,sBAAsB;AACjC,WAAW,+BAA+B;AAC1C,WAAW,4BAA4B;;;ACjBvC,SAAS,gBAAgB;;;ACAzB,IAAO,eAAQ,OAAO,OAAO,MAAM;AAAC,GAAG,EAAE,WAAW,KAAK,CAAC;;;ADG1D,IAAM,WAAW,WAAW;AAErB,IAAM,gBAAgB;AACtB,IAAM,UAAU,IAAI,SAAS;AAC7B,IAAM,UAAU,IAAI,SAAS;AAC7B,IAAM,MAAM,UAAU,OAAO;AAC7B,IAAM,OAAO,UAAU,QAAQ;AAC/B,IAAM,QAAQ,UAAU,SAAS;AACjC,IAAM,QAAQ,UAAU,SAAS;AACjC,IAAM,QAAQ,UAAU,SAAS;AACjC,IAAM,QAAQ,UAAU,SAAS;AACjC,IAAM,OAAO,UAAU,QAAQ;AAE/B,IAAM,aAAa,UAAU,cAA8B,+BAAe,oBAAoB;AAG9F,IAAM,QAAQ,UAAU,SAAS;AACjC,IAAM,QAAQ,UAAU,SAAS;AACjC,IAAM,aAAa,UAAU,cAAc;AAC3C,IAAM,MAAM,UAAU,OAAO;AAC7B,IAAM,SAAS,UAAU,UAAU;AACnC,IAAM,QAAQ,UAAU,SAAS;AACjC,IAAM,WAAW,UAAU,YAAY;AACvC,IAAM,iBAAiB,UAAU,kBAAkB;AACnD,IAAM,UAAU,UAAU,WAAW;AACrC,IAAM,aAAa,UAAU,cAAc;AAC3C,IAAM,OAAO,UAAU,QAAQ;AAC/B,IAAM,UAAU,UAAU,WAAW;AACrC,IAAM,UAAU,UAAU,WAAW;AACrC,IAAM,YAAY,UAAU,aAAa;AACzC,IAAM,UAAU,UAAU,WAA2B,oCAAoB,iBAAiB;AAC1F,IAAM,SAAyB,oBAAI,IAAI;AAKvC,IAAM,sBAAsB;AAC5B,IAAM,sBAAsB;;;AEtBnC,IAAM,iBAAiB,WAAW,SAAS;AACpC,IAAM;AAAA,EACX;AAAA,EACA,OAAAC;AAAA;AAAA,EAEA;AAAA,EACA,OAAAC;AAAA,EACA,YAAAC;AAAA;AAAA,EAEA,YAAAC;AAAA,EACA,OAAAC;AAAA,EACA,KAAAC;AAAA,EACA,QAAAC;AAAA,EACA,OAAAC;AAAA,EACA,OAAAC;AAAA,EACA,gBAAAC;AAAA,EACA,UAAAC;AAAA,EACA,MAAAC;AAAA,EACA,KAAAC;AAAA,EACA,SAAAC;AAAA,EACA,YAAAC;AAAA,EACA,OAAAC;AAAA,EACA,MAAAC;AAAA,EACA,SAAAC;AAAA,EACA,SAAAC;AAAA,EACA,WAAAC;AAAA,EACA,OAAAC;AAAA,EACA,MAAAC;AACF,IAAI;AACJ,OAAO,OAAO,gBAAgB;AAAA,EAC5B;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AACF,CAAC;AACD,IAAO,kBAAQ;;;ACvDf,WAAW,UAAU;;;ACAd,IAAM,SAAyB,uBAAO,OAAO,gCAASC,QAAO,WAAW;AAC9E,QAAM,MAAM,KAAK,IAAI;AAErB,QAAM,UAAU,KAAK,MAAM,MAAM,GAAG;AAEpC,QAAM,QAAQ,MAAM,MAAM;AAC1B,MAAI,WAAW;AACd,QAAI,cAAc,UAAU,UAAU,CAAC;AACvC,QAAI,YAAY,QAAQ,UAAU,CAAC;AACnC,QAAI,YAAY,GAAG;AAClB,oBAAc,cAAc;AAC5B,kBAAY,MAAM;AAAA,IACnB;AACA,WAAO,CAAC,aAAa,SAAS;AAAA,EAC/B;AACA,SAAO,CAAC,SAAS,KAAK;AACvB,GAhBoD,WAgBjD,EAAE,QAAQ,gCAAS,SAAS;AAE9B,SAAO,OAAO,KAAK,IAAI,IAAI,GAAG;AAC/B,GAHa,UAGX,CAAC;;;ACpBH,SAAS,oBAAoB;;;ACAtB,IAAM,aAAN,MAAiB;AAAA,EAAxB,OAAwB;AAAA;AAAA;AAAA,EACvB;AAAA,EACA,QAAQ;AAAA,EACR,QAAQ;AAAA,EACR,YAAY,IAAI;AACf,SAAK,KAAK;AAAA,EACX;AAAA,EACA,WAAW,MAAM;AAChB,SAAK,QAAQ;AACb,WAAO;AAAA,EACR;AACD;;;ACXO,IAAM,cAAN,MAAkB;AAAA,EAAzB,OAAyB;AAAA;AAAA;AAAA,EACxB;AAAA,EACA,UAAU;AAAA,EACV,OAAO;AAAA,EACP,QAAQ;AAAA,EACR,YAAY,IAAI;AACf,SAAK,KAAK;AAAA,EACX;AAAA,EACA,UAAUC,MAAK,UAAU;AACxB,gBAAY,SAAS;AACrB,WAAO;AAAA,EACR;AAAA,EACA,gBAAgB,UAAU;AACzB,gBAAY,SAAS;AACrB,WAAO;AAAA,EACR;AAAA,EACA,SAAS,GAAG,GAAG,UAAU;AACxB,gBAAY,OAAO,aAAa,cAAc,SAAS;AACvD,WAAO;AAAA,EACR;AAAA,EACA,WAAW,IAAI,IAAI,UAAU;AAC5B,gBAAY,SAAS;AACrB,WAAO;AAAA,EACR;AAAA,EACA,cAAcC,MAAK;AAClB,WAAO;AAAA,EACR;AAAA,EACA,UAAUC,QAAOD,MAAK;AACrB,WAAO;AAAA,EACR;AAAA,EACA,gBAAgB;AACf,WAAO,CAAC,KAAK,SAAS,KAAK,IAAI;AAAA,EAChC;AAAA,EACA,MAAM,KAAK,UAAU,IAAI;AACxB,QAAI,eAAe,YAAY;AAC9B,YAAM,IAAI,YAAY,EAAE,OAAO,GAAG;AAAA,IACnC;AACA,QAAI;AACH,cAAQ,IAAI,GAAG;AAAA,IAChB,QAAQ;AAAA,IAAC;AACT,UAAM,OAAO,OAAO,cAAc,GAAG;AACrC,WAAO;AAAA,EACR;AACD;;;AC1CO,IAAM,eAAe;;;AHIrB,IAAM,UAAN,MAAM,iBAAgB,aAAa;AAAA,EAL1C,OAK0C;AAAA;AAAA;AAAA,EACzC;AAAA,EACA;AAAA,EACA;AAAA,EACA,YAAY,MAAM;AACjB,UAAM;AACN,SAAK,MAAM,KAAK;AAChB,SAAK,SAAS,KAAK;AACnB,SAAK,WAAW,KAAK;AACrB,eAAW,QAAQ,CAAC,GAAG,OAAO,oBAAoB,SAAQ,SAAS,GAAG,GAAG,OAAO,oBAAoB,aAAa,SAAS,CAAC,GAAG;AAC7H,YAAM,QAAQ,KAAK,IAAI;AACvB,UAAI,OAAO,UAAU,YAAY;AAChC,aAAK,IAAI,IAAI,MAAM,KAAK,IAAI;AAAA,MAC7B;AAAA,IACD;AAAA,EACD;AAAA;AAAA,EAEA,YAAY,SAAS,MAAM,MAAM;AAChC,YAAQ,KAAK,GAAG,OAAO,IAAI,IAAI,OAAO,EAAE,GAAG,OAAO,GAAG,IAAI,OAAO,EAAE,GAAG,OAAO,EAAE;AAAA,EAC/E;AAAA,EACA,QAAQ,MAAM;AAEb,WAAO,MAAM,KAAK,GAAG,IAAI;AAAA,EAC1B;AAAA,EACA,UAAU,WAAW;AACpB,WAAO,MAAM,UAAU,SAAS;AAAA,EACjC;AAAA;AAAA,EAEA;AAAA,EACA;AAAA,EACA;AAAA,EACA,IAAI,QAAQ;AACX,WAAO,KAAK,WAAW,IAAI,WAAW,CAAC;AAAA,EACxC;AAAA,EACA,IAAI,SAAS;AACZ,WAAO,KAAK,YAAY,IAAI,YAAY,CAAC;AAAA,EAC1C;AAAA,EACA,IAAI,SAAS;AACZ,WAAO,KAAK,YAAY,IAAI,YAAY,CAAC;AAAA,EAC1C;AAAA;AAAA,EAEA,OAAO;AAAA,EACP,MAAME,MAAK;AACV,SAAK,OAAOA;AAAA,EACb;AAAA,EACA,MAAM;AACL,WAAO,KAAK;AAAA,EACb;AAAA;AAAA,EAEA,OAAO;AAAA,EACP,WAAW;AAAA,EACX,OAAO,CAAC;AAAA,EACR,QAAQ;AAAA,EACR,WAAW,CAAC;AAAA,EACZ,WAAW;AAAA,EACX,QAAQ;AAAA,EACR,MAAM;AAAA,EACN,OAAO;AAAA,EACP,IAAI,UAAU;AACb,WAAO,IAAI,YAAY;AAAA,EACxB;AAAA,EACA,IAAI,WAAW;AACd,WAAO,EAAE,MAAM,aAAa;AAAA,EAC7B;AAAA,EACA,IAAI,8BAA8B;AACjC,WAAO,oBAAI,IAAI;AAAA,EAChB;AAAA,EACA,IAAI,oBAAoB;AACvB,WAAO;AAAA,EACR;AAAA,EACA,IAAI,YAAY;AACf,WAAO;AAAA,EACR;AAAA,EACA,IAAI,mBAAmB;AACtB,WAAO;AAAA,EACR;AAAA,EACA,IAAI,mBAAmB;AACtB,WAAO;AAAA,EACR;AAAA,EACA,IAAI,WAAW;AACd,WAAO,CAAC;AAAA,EACT;AAAA,EACA,IAAI,UAAU;AACb,WAAO,CAAC;AAAA,EACT;AAAA,EACA,IAAI,YAAY;AACf,WAAO;AAAA,EACR;AAAA,EACA,IAAI,SAAS;AACZ,WAAO,CAAC;AAAA,EACT;AAAA,EACA,IAAI,iBAAiB;AACpB,WAAO,CAAC;AAAA,EACT;AAAA,EACA,oBAAoB;AACnB,WAAO;AAAA,EACR;AAAA,EACA,kBAAkB;AACjB,WAAO;AAAA,EACR;AAAA,EACA,SAAS;AACR,WAAO;AAAA,EACR;AAAA,EACA,gBAAgB;AACf,WAAO,CAAC;AAAA,EACT;AAAA;AAAA,EAEA,MAAM;AAAA,EAEN;AAAA,EACA,QAAQ;AAAA,EAER;AAAA;AAAA,EAEA,QAAQ;AACP,UAAM,0BAA0B,eAAe;AAAA,EAChD;AAAA,EACA,mBAAmB;AAClB,WAAO;AAAA,EACR;AAAA,EACA,yBAAyB;AACxB,UAAM,0BAA0B,gCAAgC;AAAA,EACjE;AAAA,EACA,OAAO;AACN,UAAM,0BAA0B,cAAc;AAAA,EAC/C;AAAA,EACA,aAAa;AACZ,UAAM,0BAA0B,oBAAoB;AAAA,EACrD;AAAA,EACA,OAAO;AACN,UAAM,0BAA0B,cAAc;AAAA,EAC/C;AAAA,EACA,QAAQ;AACP,UAAM,0BAA0B,eAAe;AAAA,EAChD;AAAA,EACA,SAAS;AACR,UAAM,0BAA0B,gBAAgB;AAAA,EACjD;AAAA,EACA,uBAAuB;AACtB,UAAM,0BAA0B,8BAA8B;AAAA,EAC/D;AAAA,EACA,cAAc;AACb,UAAM,0BAA0B,qBAAqB;AAAA,EACtD;AAAA,EACA,aAAa;AACZ,UAAM,0BAA0B,oBAAoB;AAAA,EACrD;AAAA,EACA,WAAW;AACV,UAAM,0BAA0B,kBAAkB;AAAA,EACnD;AAAA,EACA,sCAAsC;AACrC,UAAM,0BAA0B,6CAA6C;AAAA,EAC9E;AAAA,EACA,sCAAsC;AACrC,UAAM,0BAA0B,6CAA6C;AAAA,EAC9E;AAAA,EACA,aAAa;AACZ,UAAM,0BAA0B,oBAAoB;AAAA,EACrD;AAAA,EACA,YAAY;AACX,UAAM,0BAA0B,mBAAmB;AAAA,EACpD;AAAA,EACA,SAAS;AACR,UAAM,0BAA0B,gBAAgB;AAAA,EACjD;AAAA,EACA,UAAU;AACT,UAAM,0BAA0B,iBAAiB;AAAA,EAClD;AAAA;AAAA,EAEA,aAAa,EAAE,KAAqB,+BAAe,wBAAwB,EAAE;AAAA,EAC7E,SAAS;AAAA,IACR,WAAW;AAAA,IACX,UAAU;AAAA,IACV,QAAQ;AAAA,IACR,SAAS;AAAA,IACT,oBAAoB;AAAA,IACpB,gBAAgB;AAAA,IAChB,2BAA2B;AAAA,IAC3B,WAA2B,+BAAe,0BAA0B;AAAA,IACpE,aAA6B,+BAAe,4BAA4B;AAAA,EACzE;AAAA,EACA,eAAe;AAAA,IACd,UAA0B,+BAAe,+BAA+B;AAAA,IACxE,YAA4B,+BAAe,iCAAiC;AAAA,IAC5E,oBAAoC,+BAAe,yCAAyC;AAAA,EAC7F;AAAA,EACA,cAAc,OAAO,OAAO,OAAO;AAAA,IAClC,cAAc;AAAA,IACd,KAAK;AAAA,IACL,UAAU;AAAA,IACV,WAAW;AAAA,IACX,UAAU;AAAA,EACX,IAAI,EAAE,KAAK,6BAAM,GAAN,OAAQ,CAAC;AAAA;AAAA,EAEpB,aAAa;AAAA,EACb,SAAS;AAAA;AAAA,EAET,OAAO;AAAA,EACP,WAAW;AAAA,EACX,UAAU;AAAA,EACV,UAAU;AAAA,EACV,UAAU;AAAA,EACV,SAAS;AAAA,EACT,YAAY;AAAA,EACZ,SAAS;AAAA,EACT,UAAU;AAAA,EACV,UAAU;AAAA,EACV,SAAS;AAAA,EACT,YAAY;AAAA,EACZ,SAAS;AAAA;AAAA,EAET,UAAU;AAAA,EACV,eAAe;AAAA,EACf,WAAW;AAAA,EACX,gBAAgB;AAAA,EAChB,YAAY;AAAA,EACZ,gBAAgB;AAAA,EAChB,kBAAkB;AAAA,EAClB,oBAAoB;AAAA,EACpB,qBAAqB;AAAA,EACrB,QAAQ;AAAA,EACR,mBAAmB;AAAA,EACnB,YAAY;AAAA,EACZ,6BAA6B;AAAA,EAC7B,4BAA4B;AAAA,EAC5B,gBAAgB;AAAA,EAChB,cAAc;AAAA,EACd,eAAe;AAAA,EACf,kBAAkB;AAAA,EAClB,WAAW;AAAA,EACX,QAAQ;AAAA,EACR,iBAAiB;AAClB;;;AI3OA,IAAM,gBAAgB,WAAW,SAAS;AACnC,IAAM,mBAAmB,cAAc;AAC9C,IAAM,iBAAiB,iBAAiB,cAAc;AACtD,IAAM,qBAAqB,WAAW,WAAW,mBAAmB;AACpE,IAAM,eAAe,IAAI,QAAa;AAAA,EACpC,KAAK,cAAc;AAAA;AAAA,EAEnB,QAAQ,qBAAqB,eAAe,SAAS;AAAA;AAAA,EAErD,UAAU,eAAe;AAC3B,CAAC;AACM,IAAM,EAAE,MAAM,UAAU,SAAS,IAAI;AACrC,IAAM;AAAA;AAAA,EAEX;AAAA;AAAA,EAEA,QAAAC;AAAA;AAAA,EAEA;AACF,IAAI;AACG,IAAM;AAAA,EACX;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA,QAAAC;AAAA,EACA;AAAA,EACA;AACF,IAAI;AACG,IAAM;AAAA;AAAA,EAEX;AAAA;AAAA,EAEA;AAAA;AAAA,EAEA;AAAA;AAAA,EAEA;AAAA;AAAA,EAEA;AAAA;AAAA,EAEA;AAAA;AAAA,EAEA;AAAA;AAAA,EAEA;AAAA;AAAA,EAEA;AAAA;AAAA,EAEA;AAAA;AAAA,EAEA;AAAA;AAAA,EAEA;AAAA;AAAA,EAEA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA;AAAA,EAEA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA;AAAA,EAEA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA;AAAA,EAEA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA;AAAA,EAEA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA;AAAA,EAEA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA;AAAA,EAEA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AACF,IAAI,qBAAqB,iBAAiB;AAC1C,IAAM,WAAW;AAAA,EACf;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA,QAAAD;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA;AAAA,EAEA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA,QAAAC;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AACF;AACA,IAAO,kBAAQ;;;AChQf,WAAW,UAAU;;;ACKrB,eAAsB,kBACpB,MACAC,MACmB;AACnB,QAAM,WAAW,MAAMA,KAAI,GAAG,IAAI,8BAA8B;AAAA,IAC9D,MAAM,CAAC,IAAI;AAAA,EACb,CAAC;AAED,SAAO,SAAS,KAAK,CAAC;AACxB;AATsB;AActB,eAAsB,mBACpB,OACAA,MACqB;AAErB,QAAM,WAAW,MAAMA,KAAI,GAAG,IAAI,8BAA8B;AAAA,IAC9D,MAAM;AAAA,EACR,CAAC;AAED,SAAO,SAAS;AAClB;AAVsB;AAgBf,SAAS,cACd,SACA,YAAoB,KACpB,eAAuB,KACb;AACV,QAAM,SAAmB,CAAC;AAC1B,MAAI,QAAQ;AAEZ,SAAO,QAAQ,QAAQ,QAAQ;AAC7B,UAAM,MAAM,KAAK,IAAI,QAAQ,WAAW,QAAQ,MAAM;AACtD,UAAM,QAAQ,QAAQ,MAAM,OAAO,GAAG;AAGtC,QAAI,MAAM,QAAQ,QAAQ;AACxB,YAAM,aAAa,MAAM,YAAY,GAAG;AACxC,YAAM,cAAc,MAAM,YAAY,IAAI;AAC1C,YAAM,aAAa,KAAK,IAAI,YAAY,WAAW;AAEnD,UAAI,aAAa,YAAY,KAAK;AAChC,eAAO,KAAK,QAAQ,MAAM,OAAO,QAAQ,aAAa,CAAC,CAAC;AACxD,iBAAS,aAAa,IAAI;AAC1B;AAAA,MACF;AAAA,IACF;AAEA,WAAO,KAAK,KAAK;AACjB,aAAS,YAAY;AAAA,EACvB;AAEA,SAAO;AACT;AA9BgB;AAmChB,eAAsB,wBACpB,UACA,SACA,UACAA,MACe;AAEf,QAAM,SAAS,cAAc,OAAO;AAGpC,QAAM,YAAY;AAClB,WAAS,IAAI,GAAG,IAAI,OAAO,QAAQ,KAAK,WAAW;AACjD,UAAM,QAAQ,OAAO,MAAM,GAAG,IAAI,SAAS;AAC3C,UAAM,aAAa,MAAM,mBAAmB,OAAOA,IAAG;AAGtD,UAAM,UAAU,MAAM,IAAI,CAAC,OAAO,SAAS;AAAA,MACzC,IAAI,GAAG,QAAQ,UAAU,IAAI,GAAG;AAAA,MAChC,QAAQ,WAAW,GAAG;AAAA,MACtB,UAAU;AAAA,QACR;AAAA,QACA,SAAS;AAAA,QACT,YAAY,IAAI;AAAA,QAChB,OAAO,SAAS;AAAA,QAChB,MAAM,SAAS;AAAA,MACjB;AAAA,IACF,EAAE;AAGF,UAAMA,KAAI,UAAU,OAAO,OAAO;AAAA,EACpC;AACF;AA/BsB;AAoCtB,eAAsB,qBACpB,OACA,UACA,OAAe,GACfA,MAC0B;AAE1B,QAAM,iBAAiB,MAAM,kBAAkB,OAAOA,IAAG;AAGzD,QAAM,UAAU,MAAMA,KAAI,UAAU,MAAM,gBAAgB;AAAA,IACxD;AAAA,IACA,QAAQ,WAAW,EAAE,SAAS,IAAI;AAAA,EACpC,CAAC;AAGD,SAAO,QAAQ,QAAQ,IAAI,CAAC,WAAW;AAAA,IACrC,IAAI,MAAM;AAAA,IACV,UAAU,MAAM,SAAS;AAAA,IACzB,SAAS,MAAM,SAAS;AAAA,IACxB,WAAW,MAAM;AAAA,IACjB,UAAU;AAAA,MACR,MAAM,MAAM,SAAS;AAAA,MACrB,WAAW,MAAM,SAAS;AAAA,MAC1B,SAAS,MAAM,SAAS;AAAA,IAC1B;AAAA,EACF,EAAE;AACJ;AA3BsB;AAgCtB,eAAsB,uBACpB,UACAA,MACe;AAGf,QAAM,UAAU,MAAMA,KAAI,UAAU,MAAM,IAAI,MAAM,IAAI,EAAE,KAAK,CAAC,GAAG;AAAA,IACjE,MAAM;AAAA,IACN,QAAQ,EAAE,SAAS;AAAA,EACrB,CAAC;AAED,QAAM,MAAM,QAAQ,QAAQ,IAAI,CAAC,MAAM,EAAE,EAAE;AAC3C,MAAI,IAAI,SAAS,GAAG;AAClB,UAAMA,KAAI,UAAU,YAAY,GAAG;AAAA,EACrC;AACF;AAfsB;;;ACtItB,eAAsB,aACpB,QACA,cACAC,MACA,UAII,CAAC,GACY;AACjB,MAAI,CAACA,MAAK;AACR,UAAM,IAAI,MAAM,0BAA0B;AAAA,EAC5C;AAEA,QAAM,WAAsB,CAAC;AAE7B,MAAI,cAAc;AAChB,aAAS,KAAK;AAAA,MACZ,MAAM;AAAA,MACN,SAAS;AAAA,IACX,CAAC;AAAA,EACH;AAEA,WAAS,KAAK;AAAA,IACZ,MAAM;AAAA,IACN,SAAS;AAAA,EACX,CAAC;AAED,QAAM,WAAW,MAAMA,KAAI,GAAG,IAAI,4CAA4C;AAAA,IAC5E;AAAA,IACA,aAAa,QAAQ,eAAe;AAAA,IACpC,YAAY,QAAQ,aAAa;AAAA,IACjC,QAAQ,QAAQ,UAAU;AAAA,EAC5B,CAAC;AAED,MAAI,QAAQ,QAAQ;AAElB,WAAO;AAAA,EACT;AAEA,SAAO,SAAS;AAClB;AAzCsB;AA8CtB,eAAsB,oBACpB,UACAA,MACA,UAGI,CAAC,GACY;AACjB,QAAM,WAAW,MAAMA,KAAI,GAAG,IAAI,4CAA4C;AAAA,IAC5E;AAAA,IACA,aAAa,QAAQ,eAAe;AAAA,IACpC,YAAY,QAAQ,aAAa;AAAA,EACnC,CAAC;AAED,SAAO,SAAS;AAClB;AAfsB;AAoBtB,eAAsB,aACpB,QACA,cACA,YACAA,MACY;AACZ,QAAM,aAAa,GAAG,MAAM;AAAA;AAAA;AAAA,EAA+D,UAAU;AAErG,QAAM,WAAW,MAAM,aAAa,YAAY,cAAcA,MAAK;AAAA,IACjE,aAAa;AAAA;AAAA,EACf,CAAC;AAGD,QAAM,YAAY,SAAS,MAAM,0BAA0B,KAAK,SAAS,MAAM,aAAa;AAE5F,MAAI,CAAC,WAAW;AACd,UAAM,IAAI,MAAM,sCAAsC;AAAA,EACxD;AAEA,QAAM,UAAU,UAAU,CAAC,KAAK,UAAU,CAAC;AAC3C,SAAO,KAAK,MAAM,OAAO;AAC3B;AArBsB;;;AC/DtB,eAAsB,iBACpB,SACAC,MACuB;AACvB,QAAM,EAAE,UAAU,SAAS,sBAAsB,CAAC,EAAE,IAAI;AAGxD,QAAM,iBAAiB,MAAM,qBAAqB,SAAS,UAAU,GAAGA,IAAG;AAG3E,QAAMC,WAAU,eACb,IAAI,CAAC,OAAO,QAAQ,WAAW,MAAM,CAAC;AAAA,EAAM,MAAM,OAAO,EAAE,EAC3D,KAAK,MAAM;AAGd,QAAM,eAAe;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAMrBA,QAAO;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAUP,QAAM,WAAsB;AAAA,IAC1B,EAAE,MAAM,UAAU,SAAS,aAAa;AAAA,IACxC,GAAG;AAAA,IACH,EAAE,MAAM,QAAQ,SAAS,QAAQ;AAAA,EACnC;AAGA,QAAM,WAAW,MAAM,oBAAoB,UAAUD,MAAK;AAAA,IACxD,aAAa;AAAA,IACb,WAAW;AAAA,EACb,CAAC;AAGD,QAAM,UAA4B,eAAe,IAAI,CAAC,OAAO,SAAS;AAAA,IACpE,UAAU,MAAM;AAAA,IAChB,OAAO,MAAM,QAAQ,UAAU,GAAG,GAAG,IAAI;AAAA,IACzC,MAAM,MAAM,SAAS;AAAA,IACrB,WAAW,MAAM,SAAS;AAAA,IAC1B,YAAY,IAAI,OAAO;AAAA;AAAA,EACzB,EAAE;AAGF,QAAM,iBAAiB,OAAO,WAAW;AAEzC,SAAO;AAAA,IACL;AAAA,IACA;AAAA,IACA;AAAA,EACF;AACF;AA5DsB;AAiEtB,eAAsB,yBACpB,gBACA,SACAA,MACuB;AAEvB,QAAM,aAAa,QAAQ,cAAc;AACzC,QAAM,cAAc,MAAMA,KAAI,MAAM,IAAI,UAAU;AAElD,QAAM,sBAAiC,cAAc,KAAK,MAAM,WAAW,IAAI,CAAC;AAGhF,QAAM,cAAc,aAAa,cAAc;AAC/C,QAAM,eAAe,MAAMA,KAAI,MAAM,IAAI,WAAW;AACpD,QAAM,WAAW,eAAe,KAAK,MAAM,YAAY,IAAI,CAAC;AAE5D,QAAM,WAAW,SAAS;AAG1B,QAAM,WAAW,MAAM;AAAA,IACrB;AAAA,MACE;AAAA,MACA;AAAA,MACA;AAAA,IACF;AAAA,IACAA;AAAA,EACF;AAGA,sBAAoB;AAAA,IAClB,EAAE,MAAM,QAAQ,SAAS,QAAQ;AAAA,IACjC,EAAE,MAAM,aAAa,SAAS,SAAS,SAAS;AAAA,EAClD;AAGA,QAAMA,KAAI,MAAM,IAAI,YAAY,KAAK,UAAU,mBAAmB,GAAG;AAAA,IACnE,eAAe;AAAA,EACjB,CAAC;AAED,SAAO;AACT;AAxCsB;;;AC1DtB,eAAsB,mBACpB,SACAE,MAC6B;AAC7B,QAAM,EAAE,UAAU,aAAa,CAAC,GAAG,aAAa,eAAe,IAAI;AAGnE,QAAM,YAAY,MAAM,qBAAqB,gCAAgC,UAAU,IAAIA,IAAG;AAE9F,QAAM,cAAc,UAAU,IAAI,CAAC,MAAM,EAAE,OAAO,EAAE,KAAK,MAAM;AAG/D,QAAM,WAAW,MAAM,iBAAiB,aAAa,YAAYA,IAAG;AAGpE,QAAM,YAAY,MAAM,iBAAiB,aAAa,YAAYA,IAAG;AAGrE,QAAM,WAAW,MAAM,iBAAiB,aAAaA,IAAG;AAGxD,QAAM,aAAa,MAAM,kBAAkB,aAAaA,IAAG;AAG3D,QAAM,oBAAoB,MAAM,0BAA0B,aAAa,YAAYA,IAAG;AAGtF,QAAMC,SAAQ,MAAM,cAAc,aAAaD,IAAG;AAElD,SAAO;AAAA,IACL,OAAAC;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF;AACF;AArCsB;AA0CtB,eAAe,iBACb,SACA,YACAD,MACiB;AACjB,QAAM,eAAe,gEAAgE,UAAU;AAAA;AAAA;AAAA;AAAA;AAAA;AAO/F,SAAO,aAAa,SAAS,cAAcA,MAAK;AAAA,IAC9C,aAAa;AAAA,IACb,WAAW;AAAA,EACb,CAAC;AACH;AAhBe;AAqBf,eAAe,iBACb,SACA,YACAA,MACqB;AACrB,QAAM,eAAe;AAAA,EACrB,WAAW,SAAS,IAAI,0BAA0B,WAAW,KAAK,IAAI,CAAC,KAAK,EAAE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAgB9E,QAAM,SAAS;AAAA;AAAA,EAA0B,QAAQ,UAAU,GAAG,GAAI,CAAC;AAEnE,QAAM,SAAS;AAEf,QAAM,SAAS,MAAM,aAAyB,QAAQ,cAAc,QAAQA,IAAG;AAG/E,SAAO,OAAO,KAAK,CAAC,GAAG,MAAM,EAAE,aAAa,EAAE,UAAU;AAC1D;AA9Be;AAmCf,eAAe,iBAAiB,SAAiBA,MAAgD;AAC/F,QAAM,eAAe;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAkBrB,QAAM,SAAS;AAAA;AAAA,EAAuC,QAAQ,UAAU,GAAG,GAAI,CAAC;AAEhF,MAAI;AACF,UAAM,WAAW,MAAM;AAAA,MACrB;AAAA,MACA;AAAA,MACA;AAAA,MACAA;AAAA,IACF;AAGA,WAAO,SAAS,SAAS,IAAI,WAAW;AAAA,EAC1C,QAAQ;AACN,WAAO;AAAA,EACT;AACF;AAlCe;AAuCf,eAAe,kBAAkB,SAAiBA,MAAqC;AACrF,QAAM,eAAe;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAmBrB,QAAM,SAAS;AAAA;AAAA,EAA0B,QAAQ,UAAU,GAAG,GAAI,CAAC;AAEnE,QAAM,SAAS;AAEf,SAAO,aAA+B,QAAQ,cAAc,QAAQA,IAAG;AACzE;AAzBe;AA8Bf,eAAe,0BACb,SACA,YACAA,MACmB;AACnB,QAAM,eAAe;AAAA,oBACH,UAAU;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAU5B,QAAM,SAAS;AAAA;AAAA,EAA6B,QAAQ,UAAU,GAAG,GAAI,CAAC;AAEtE,QAAM,SAAS;AAEf,SAAO,aAAuB,QAAQ,cAAc,QAAQA,IAAG;AACjE;AArBe;AA0Bf,eAAe,cAAc,SAAiBA,MAA2B;AACvE,QAAM,eAAe;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAQrB,QAAM,SAAS,QAAQ,UAAU,GAAG,GAAI;AAExC,SAAO,aAAa,QAAQ,cAAcA,MAAK;AAAA,IAC7C,aAAa;AAAA,IACb,WAAW;AAAA,EACb,CAAC;AACH;AAfe;AAoBf,eAAsB,kBACpB,YACA,YACAA,MAQA;AACA,QAAM,eAAe,YAAY,UAAU;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAW3C,QAAM,SAAS;AAAA,SACR,WAAW,KAAK;AAAA,cACX,WAAW,UAAU,IAAI,CAAC,MAAM,EAAE,KAAK,EAAE,KAAK,IAAI,CAAC;AAAA,8BACnC,WAAW,WAAW,MAAM;AAAA,sBACpC,WAAW,kBAAkB,MAAM;AAEvD,QAAM,SAAS;AAEf,SAAO,aAAa,QAAQ,cAAc,QAAQA,IAAG;AACvD;AAhCsB;;;ACvNtB,eAAsB,mBACpB,SACAE,MACsC;AACtC,QAAM,EAAE,UAAU,OAAAC,SAAQ,IAAI,aAAa,UAAU,SAAS,CAAC,EAAE,IAAI;AAGrE,QAAM,cACJ,OAAO,SAAS,IACZ,gCAAgC,OAAO,KAAK,IAAI,CAAC,KACjD;AAEN,QAAM,SAAS,MAAM,qBAAqB,aAAa,UAAU,IAAID,IAAG;AACxE,QAAM,UAAU,OAAO,IAAI,CAAC,MAAM,EAAE,OAAO,EAAE,KAAK,MAAM;AAGxD,QAAM,YAAY;AAClB,QAAM,WAAiC,CAAC;AAExC,WAAS,IAAI,GAAG,IAAIC,QAAO,KAAK,WAAW;AACzC,UAAM,aAAa,KAAK,IAAI,WAAWA,SAAQ,CAAC;AAChD,UAAM,QAAQ,MAAM,uBAAuB,SAAS,YAAY,YAAY,QAAQD,IAAG;AACvF,aAAS,KAAK,GAAG,KAAK;AAAA,EACxB;AAGA,QAAM,cAAc,sBAAsB,QAAQ;AAClD,QAAM,cAAc,MAAM,wBAAwB,aAAaA,IAAG;AAGlE,QAAM,cAAc,MAAM,eAAe,UAAU,SAASA,IAAG;AAE/D,SAAO;AAAA,IACL,OAAO,YAAY,MAAM,GAAGC,MAAK;AAAA,IACjC,UAAU;AAAA,MACR,gBAAgB,YAAY;AAAA,MAC5B;AAAA,MACA;AAAA,IACF;AAAA,EACF;AACF;AAxCsB;AA6CtB,eAAe,uBACb,SACAA,QACA,YACA,QACAD,MAC+B;AAC/B,QAAM,eAAe;AAAA;AAAA,iBAENC,MAAK;AAAA,gBACN,UAAU;AAAA,EACxB,OAAO,SAAS,IAAI,mBAAmB,OAAO,KAAK,IAAI,CAAC,KAAK,EAAE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAiB/D,QAAM,SAAS;AAAA;AAAA,EAAuB,QAAQ,UAAU,GAAG,GAAI,CAAC;AAEhE,QAAM,SAAS;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AASf,SAAO,aAAmC,QAAQ,cAAc,QAAQD,IAAG;AAC7E;AAxCe;AA6Cf,SAAS,sBAAsB,OAAmD;AAChF,QAAM,SAA+B,CAAC;AAEtC,aAAW,QAAQ,OAAO;AAExB,UAAM,cAAc,OAAO,KAAK,CAAC,aAAa;AAC5C,YAAM,aAAa,wBAAwB,KAAK,OAAO,SAAS,KAAK;AACrE,aAAO,aAAa;AAAA,IACtB,CAAC;AAED,QAAI,CAAC,aAAa;AAChB,aAAO,KAAK,IAAI;AAAA,IAClB;AAAA,EACF;AAEA,SAAO;AACT;AAhBS;AAqBT,SAAS,wBAAwB,OAAe,OAAuB;AACrE,QAAM,SAAS,IAAI,IAAI,MAAM,YAAY,EAAE,MAAM,KAAK,CAAC;AACvD,QAAM,SAAS,IAAI,IAAI,MAAM,YAAY,EAAE,MAAM,KAAK,CAAC;AAEvD,QAAM,eAAe,IAAI,IAAI,CAAC,GAAG,MAAM,EAAE,OAAO,CAAC,MAAM,OAAO,IAAI,CAAC,CAAC,CAAC;AACrE,QAAM,QAAQ,oBAAI,IAAI,CAAC,GAAG,QAAQ,GAAG,MAAM,CAAC;AAE5C,SAAO,aAAa,OAAO,MAAM;AACnC;AARS;AAaT,eAAe,wBACb,OACAA,MAC+B;AAI/B,MAAI,MAAM,UAAU,IAAI;AAEtB,UAAM,eAAe;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AASrB,QAAI;AACF,YAAM,YAAY,KAAK,UAAU,MAAM,IAAI,CAAC,OAAO,EAAE,OAAO,EAAE,OAAO,MAAM,EAAE,KAAK,EAAE,CAAC;AACrF,YAAM,SAAS,MAAM;AAAA,QACnB;AAAA,QACA;AAAA,QACA;AAAA,QACAA;AAAA,MACF;AAGA,YAAM,SAAS,MAAM,IAAI,CAAC,MAAM,SAAS;AAAA,QACvC;AAAA,QACA,OAAO,OAAO,GAAG,KAAK;AAAA,MACxB,EAAE;AAEF,aAAO,KAAK,CAAC,GAAG,MAAM,EAAE,QAAQ,EAAE,KAAK;AACvC,aAAO,OAAO,IAAI,CAAC,MAAM,EAAE,IAAI;AAAA,IACjC,QAAQ;AAEN,aAAO;AAAA,IACT;AAAA,EACF;AAGA,SAAO;AACT;AA3Ce;AAgDf,eAAe,eACb,UACA,SACAA,MACiB;AAEjB,QAAM,eAAe;AAAA;AAGrB,QAAM,SAAS,QAAQ,UAAU,GAAG,GAAG;AAEvC,SAAO,aAAa,QAAQ,cAAcA,MAAK;AAAA,IAC7C,aAAa;AAAA,IACb,WAAW;AAAA,EACb,CAAC;AACH;AAfe;AAoBf,eAAsB,mBACpB,UACAC,QACAD,MAC+B;AAC/B,QAAM,SAAS,MAAM,qBAAqB,uCAAuC,UAAU,IAAIA,IAAG;AAClG,QAAM,UAAU,OAAO,IAAI,CAAC,MAAM,EAAE,OAAO,EAAE,KAAK,MAAM;AAExD,QAAM,eAAe,UAAUC,MAAK;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAsBpC,QAAM,SAAS;AAAA;AAAA,EAAe,QAAQ,UAAU,GAAG,GAAI,CAAC;AAExD,QAAM,SAAS;AAEf,SAAO,aAAmC,QAAQ,cAAc,QAAQD,IAAG;AAC7E;AAnCsB;;;AC/LtB,eAAsB,sBACpB,SACAE,MACgC;AAChC,QAAM,EAAE,UAAU,QAAQ,kBAAkB,WAAW,IAAI,IAAI;AAG/D,QAAM,SAAS,MAAM,qBAAqB,qDAAqD,UAAU,IAAIA,IAAG;AAChH,QAAM,UAAU,OAAO,IAAI,CAAC,MAAM,EAAE,OAAO,EAAE,KAAK,MAAM;AAGxD,QAAM,SAAS,MAAM,uBAAuB,SAAS,OAAO,UAAUA,IAAG;AAGzE,QAAM,cAAc,MAAM,iBAAiB,QAAQA,IAAG;AAEtD,SAAO;AAAA,IACL,UAAU,YAAY;AAAA,IACtB,YAAY,OAAO;AAAA,IACnB,UAAU,OAAO;AAAA,IACjB,UAAU,YAAY;AAAA,EACxB;AACF;AAtBsB;AA2BtB,eAAe,uBACb,SACA,OACA,gBACAA,MAIC;AACD,QAAM,iBAAiB;AACvB,QAAM,cAAe,iBAAiB,KAAM;AAE5C,MAAI,eAAe;AAEnB,UAAQ,OAAO;AAAA,IACb,KAAK;AACH,qBAAe;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,yBAYI,KAAK,MAAM,WAAW,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAM1C;AAAA,IAEF,KAAK;AACH,qBAAe;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,yBASI,KAAK,MAAM,WAAW,CAAC;AAAA;AAAA;AAAA;AAAA;AAK1C;AAAA,IAEF,KAAK;AACH,qBAAe;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,yBAWI,KAAK,MAAM,WAAW,CAAC;AAAA;AAAA;AAAA;AAI1C;AAAA,EACJ;AAEA,QAAM,SAAS;AAAA;AAAA,EAA0B,QAAQ,UAAU,GAAG,GAAK,CAAC;AAEpE,QAAM,WAAW,MAAM,aAAa,QAAQ,cAAcA,MAAK;AAAA,IAC7D,aAAa;AAAA;AAAA,IACb,WAAW,KAAK,KAAK,cAAc,GAAG;AAAA,EACxC,CAAC;AAGD,QAAM,QAAQ,SAAS,MAAM,IAAI,EAAE,OAAO,CAAC,SAAS,KAAK,KAAK,CAAC;AAC/D,QAAM,WAA0C,oBAAI,IAAI;AAExD,MAAI,YAAY;AAChB,aAAW,QAAQ,OAAO;AACxB,UAAM,QAAQ,KAAK,MAAM,oBAAoB;AAC7C,QAAI,CAAC,MAAO;AAEZ,UAAM,CAAC,EAAE,SAAS,IAAI,IAAI;AAC1B,UAAM,QAAQ,KAAK,MAAM,KAAK,EAAE;AAChC,UAAM,kBAAmB,QAAQ,iBAAkB;AAEnD,QAAI,CAAC,SAAS,IAAI,OAAO,GAAG;AAC1B,eAAS,IAAI,SAAS,CAAC,CAAC;AAAA,IAC1B;AAEA,aAAS,IAAI,OAAO,EAAG,KAAK;AAAA,MAC1B;AAAA,MACA,MAAM,KAAK,KAAK;AAAA,IAClB,CAAC;AAED,iBAAa;AAAA,EACf;AAGA,QAAM,WAAsB,MAAM,KAAK,SAAS,QAAQ,CAAC,EAAE,IAAI,CAAC,CAAC,MAAM,IAAI,GAAG,SAAS;AAAA,IACrF;AAAA,IACA,OAAO,mBAAmB,MAAM,GAAG;AAAA,IACnC,UAAU;AAAA,EACZ,EAAE;AAEF,SAAO;AAAA,IACL;AAAA,IACA,gBAAgB;AAAA,EAClB;AACF;AAnHe;AAwHf,eAAe,iBACb,QACAA,MACiD;AAEjD,QAAM,cAID,CAAC;AAEN,aAAW,WAAW,OAAO,UAAU;AACrC,eAAW,WAAW,QAAQ,UAAU;AACtC,kBAAY,KAAK;AAAA,QACf,WAAW,QAAQ;AAAA,QACnB,MAAM,QAAQ;AAAA,QACd,OAAO,QAAQ;AAAA,MACjB,CAAC;AAAA,IACH;AAAA,EACF;AAEA,cAAY,KAAK,CAAC,GAAG,MAAM,EAAE,YAAY,EAAE,SAAS;AAGpD,QAAM,cAA6B,CAAC;AACpC,MAAI,gBAAgB;AAEpB,aAAW,WAAW,aAAa;AACjC,QAAI;AAGF,YAAM,cAAc,MAAMA,KAAI,GAAG,IAAI,wBAAwB;AAAA,QAC3D,MAAM,QAAQ;AAAA,QACd,aAAa;AAAA,QACb,aAAa;AAAA,MACf,CAAC;AAUD,YAAM,cAAc,MAAM,0BAA0B,QAAQ,MAAM,QAAQ,OAAOA,IAAG;AACpF,kBAAY,KAAK,WAAW;AAG5B,YAAM,QAAQ,QAAQ,KAAK,MAAM,KAAK,EAAE;AACxC,uBAAkB,QAAQ,MAAO;AAAA,IACnC,SAASC,QAAO;AACd,cAAQ,MAAM,cAAcA,MAAK;AAAA,IAEnC;AAAA,EACF;AAGA,QAAM,gBAAgB,oBAAoB,WAAW;AAGrD,MAAI,WAAW;AAEf,MAAID,KAAI,cAAc;AACpB,UAAM,WAAW,mBAAmB,OAAO,WAAW,CAAC;AACvD,UAAMA,KAAI,aAAa,IAAI,UAAU,eAAe;AAAA,MAClD,cAAc;AAAA,QACZ,aAAa;AAAA,MACf;AAAA,IACF,CAAC;AACD,eAAW,6BAA6B,QAAQ;AAAA,EAClD,OAAO;AAEL,UAAM,cAAc,KAAK,OAAO,aAAa,GAAG,IAAI,WAAW,aAAa,CAAC,CAAC;AAC9E,eAAW,0BAA0B,WAAW;AAAA,EAClD;AAEA,SAAO;AAAA,IACL;AAAA,IACA,UAAU;AAAA,EACZ;AACF;AAjFe;AAsFf,eAAe,0BACb,MACA,OACAA,MACsB;AAyBtB,SAAO,IAAI,YAAY,CAAC;AAC1B;AA9Be;AAmCf,SAAS,oBAAoB,SAAqC;AAEhE,QAAM,cAAc,QAAQ,OAAO,CAAC,KAAK,QAAQ,MAAM,IAAI,YAAY,CAAC;AAGxE,QAAM,WAAW,IAAI,WAAW,WAAW;AAC3C,MAAI,SAAS;AAEb,aAAW,UAAU,SAAS;AAC5B,aAAS,IAAI,IAAI,WAAW,MAAM,GAAG,MAAM;AAC3C,cAAU,OAAO;AAAA,EACnB;AAEA,SAAO,SAAS;AAClB;AAdS;AAmBT,SAAS,mBAAmB,MAAc,OAAuB;AAI/D,QAAM,WAAmC;AAAA,IACvC,MAAM;AAAA,IACN,OAAO;AAAA,IACP,WAAW;AAAA,IACX,OAAO;AAAA,IACP,KAAK;AAAA,EACP;AAEA,SAAO,SAAS,IAAI,KAAK,SAAS,KAAK;AACzC;AAbS;;;ACjST,IAAO,kBAAQ;AAAA,EACb,MAAM,MAAM,SAAkBE,MAA6B;AAEzD,UAAM,cAAc;AAAA,MAClB,+BAA+B;AAAA,MAC/B,gCAAgC;AAAA,MAChC,gCAAgC;AAAA,IAClC;AAGA,QAAI,QAAQ,WAAW,WAAW;AAChC,aAAO,IAAI,SAAS,MAAM,EAAE,SAAS,YAAY,CAAC;AAAA,IACpD;AAEA,QAAI;AACF,YAAM,MAAM,IAAI,IAAI,QAAQ,GAAG;AAC/B,YAAM,OAAO,IAAI;AAGjB,cAAQ,MAAM;AAAA;AAAA,QAEZ,KAAK,SAAS;AACZ,iBAAO,aAAa,EAAE,QAAQ,MAAM,WAAW,KAAK,IAAI,EAAE,GAAG,KAAK,WAAW;AAAA;AAAA,QAG/E,MAAK,SAAS,2BAA2B,QAAQ,WAAW;AAC1D,iBAAO,sBAAsB,SAASA,MAAK,WAAW;AAAA,QAExD,MAAK,SAAS,4BAA4B,QAAQ,WAAW;AAC3D,iBAAO,uBAAuB,SAASA,MAAK,WAAW;AAAA;AAAA,QAGzD,MAAK,SAAS,eAAe,QAAQ,WAAW;AAC9C,iBAAO,WAAW,SAASA,MAAK,WAAW;AAAA,QAE7C,MAAK,SAAS,wBAAwB,QAAQ,WAAW;AACvD,iBAAO,mBAAmB,SAASA,MAAK,WAAW;AAAA;AAAA,QAGrD,MAAK,SAAS,+BAA+B,QAAQ,WAAW;AAC9D,iBAAO,yBAAyB,SAASA,MAAK,WAAW;AAAA,QAE3D,MAAK,SAAS,2BAA2B,QAAQ,WAAW;AAC1D,iBAAO,wBAAwB,SAASA,MAAK,WAAW;AAAA;AAAA,QAG1D,MAAK,SAAS,8BAA8B,QAAQ,WAAW;AAC7D,iBAAO,yBAAyB,SAASA,MAAK,WAAW;AAAA,QAE3D,MAAK,SAAS,oCAAoC,QAAQ,WAAW;AACnE,iBAAO,yBAAyB,SAASA,MAAK,WAAW;AAAA;AAAA,QAG3D,MAAK,SAAS,kCAAkC,QAAQ,WAAW;AACjE,iBAAO,4BAA4B,SAASA,MAAK,WAAW;AAAA,QAE9D;AACE,iBAAO,aAAa,EAAE,OAAO,YAAY,GAAG,KAAK,WAAW;AAAA,MAChE;AAAA,IACF,SAASC,QAAO;AACd,cAAQ,MAAM,2BAA2BA,MAAK;AAC9C,aAAO;AAAA,QACL;AAAA,UACE,OAAO;AAAA,UACP,SAASA,kBAAiB,QAAQA,OAAM,UAAU;AAAA,QACpD;AAAA,QACA;AAAA,QACA;AAAA,MACF;AAAA,IACF;AAAA,EACF;AACF;AAOA,eAAe,sBACb,SACAD,MACA,aACmB;AACnB,QAAM,EAAE,UAAU,SAAS,SAAS,IAAI,MAAM,QAAQ,KAAK;AAE3D,MAAI,CAAC,YAAY,CAAC,SAAS;AACzB,WAAO,aAAa,EAAE,OAAO,0BAA0B,GAAG,KAAK,WAAW;AAAA,EAC5E;AAEA,QAAM,wBAAwB,UAAU,SAAS,UAAUA,IAAG;AAE9D,SAAO;AAAA,IACL,EAAE,SAAS,MAAM,SAAS,iCAAiC;AAAA,IAC3D;AAAA,IACA;AAAA,EACF;AACF;AAlBe;AAuBf,eAAe,uBACb,SACAA,MACA,aACmB;AACnB,QAAM,EAAE,SAAS,IAAI,MAAM,QAAQ,KAAK;AAExC,MAAI,CAAC,UAAU;AACb,WAAO,aAAa,EAAE,OAAO,mBAAmB,GAAG,KAAK,WAAW;AAAA,EACrE;AAEA,QAAM,uBAAuB,UAAUA,IAAG;AAE1C,SAAO;AAAA,IACL,EAAE,SAAS,MAAM,SAAS,kCAAkC;AAAA,IAC5D;AAAA,IACA;AAAA,EACF;AACF;AAlBe;AAuBf,eAAe,WACb,SACAA,MACA,aACmB;AACnB,QAAM,cAAc,MAAM,QAAQ,KAAK;AAEvC,MAAI,CAAC,YAAY,YAAY,CAAC,YAAY,SAAS;AACjD,WAAO,aAAa,EAAE,OAAO,0BAA0B,GAAG,KAAK,WAAW;AAAA,EAC5E;AAEA,QAAM,WAAW,MAAM,iBAAiB,aAAaA,IAAG;AAExD,SAAO,aAAa,UAAU,KAAK,WAAW;AAChD;AAde;AAmBf,eAAe,mBACb,SACAA,MACA,aACmB;AACnB,QAAM,EAAE,gBAAgB,QAAQ,IAAI,MAAM,QAAQ,KAAK;AAEvD,MAAI,CAAC,kBAAkB,CAAC,SAAS;AAC/B,WAAO,aAAa,EAAE,OAAO,0BAA0B,GAAG,KAAK,WAAW;AAAA,EAC5E;AAEA,QAAM,WAAW,MAAM,yBAAyB,gBAAgB,SAASA,IAAG;AAE5E,SAAO,aAAa,UAAU,KAAK,WAAW;AAChD;AAde;AAmBf,eAAe,yBACb,SACAA,MACA,aACmB;AACnB,QAAM,oBAAoB,MAAM,QAAQ,KAAK;AAE7C,MAAI,CAAC,kBAAkB,UAAU;AAC/B,WAAO,aAAa,EAAE,OAAO,mBAAmB,GAAG,KAAK,WAAW;AAAA,EACrE;AAEA,QAAM,aAAa,MAAM,mBAAmB,mBAAmBA,IAAG;AAElE,SAAO,aAAa,YAAY,KAAK,WAAW;AAClD;AAde;AAmBf,eAAe,wBACb,SACAA,MACA,aACmB;AACnB,QAAM,EAAE,YAAY,WAAW,IAAI,MAAM,QAAQ,KAAK;AAEtD,MAAI,CAAC,cAAc,CAAC,YAAY;AAC9B,WAAO,aAAa,EAAE,OAAO,0BAA0B,GAAG,KAAK,WAAW;AAAA,EAC5E;AAEA,QAAM,OAAO,MAAM,kBAAkB,YAAY,YAAYA,IAAG;AAEhE,SAAO,aAAa,MAAM,KAAK,WAAW;AAC5C;AAde;AAmBf,eAAe,yBACb,SACAA,MACA,aACmB;AACnB,QAAM,mBAAmB,MAAM,QAAQ,KAAK;AAE5C,MAAI,CAAC,iBAAiB,UAAU;AAC9B,WAAO,aAAa,EAAE,OAAO,mBAAmB,GAAG,KAAK,WAAW;AAAA,EACrE;AAEA,QAAM,aAAa,MAAM,mBAAmB,kBAAkBA,IAAG;AAEjE,SAAO,aAAa,YAAY,KAAK,WAAW;AAClD;AAde;AAmBf,eAAe,yBACb,SACAA,MACA,aACmB;AACnB,QAAM,EAAE,UAAU,OAAAE,OAAM,IAAI,MAAM,QAAQ,KAAK;AAE/C,MAAI,CAAC,UAAU;AACb,WAAO,aAAa,EAAE,OAAO,mBAAmB,GAAG,KAAK,WAAW;AAAA,EACrE;AAEA,QAAM,QAAQ,MAAM,mBAAmB,UAAUA,UAAS,IAAIF,IAAG;AAEjE,SAAO,aAAa,EAAE,MAAM,GAAG,KAAK,WAAW;AACjD;AAde;AAmBf,eAAe,4BACb,SACAA,MACA,aACmB;AACnB,QAAM,eAAe,MAAM,QAAQ,KAAK;AAExC,MAAI,CAAC,aAAa,UAAU;AAC1B,WAAO,aAAa,EAAE,OAAO,mBAAmB,GAAG,KAAK,WAAW;AAAA,EACrE;AAEA,QAAM,gBAAgB,MAAM,sBAAsB,cAAcA,IAAG;AAEnE,SAAO,aAAa,eAAe,KAAK,WAAW;AACrD;AAde;AAqBf,SAAS,aACP,MACA,SAAiB,KACjB,cAAsC,CAAC,GAC7B;AACV,SAAO,IAAI,SAAS,KAAK,UAAU,IAAI,GAAG;AAAA,IACxC;AAAA,IACA,SAAS;AAAA,MACP,gBAAgB;AAAA,MAChB,GAAG;AAAA,IACL;AAAA,EACF,CAAC;AACH;AAZS;;;AC7QT,IAAM,YAAwB,8BAAO,SAASG,MAAK,MAAM,kBAAkB;AAC1E,MAAI;AACH,WAAO,MAAM,cAAc,KAAK,SAASA,IAAG;AAAA,EAC7C,UAAE;AACD,QAAI;AACH,UAAI,QAAQ,SAAS,QAAQ,CAAC,QAAQ,UAAU;AAC/C,cAAM,SAAS,QAAQ,KAAK,UAAU;AACtC,eAAO,EAAE,MAAM,OAAO,KAAK,GAAG,MAAM;AAAA,QAAC;AAAA,MACtC;AAAA,IACD,SAAS,GAAG;AACX,cAAQ,MAAM,4CAA4C,CAAC;AAAA,IAC5D;AAAA,EACD;AACD,GAb8B;AAe9B,IAAO,6CAAQ;;;ACRf,SAAS,YAAY,GAAmB;AACvC,SAAO;AAAA,IACN,MAAM,GAAG;AAAA,IACT,SAAS,GAAG,WAAW,OAAO,CAAC;AAAA,IAC/B,OAAO,GAAG;AAAA,IACV,OAAO,GAAG,UAAU,SAAY,SAAY,YAAY,EAAE,KAAK;AAAA,EAChE;AACD;AAPS;AAUT,IAAM,YAAwB,8BAAO,SAASC,MAAK,MAAM,kBAAkB;AAC1E,MAAI;AACH,WAAO,MAAM,cAAc,KAAK,SAASA,IAAG;AAAA,EAC7C,SAAS,GAAQ;AAChB,UAAMC,SAAQ,YAAY,CAAC;AAC3B,WAAO,SAAS,KAAKA,QAAO;AAAA,MAC3B,QAAQ;AAAA,MACR,SAAS,EAAE,+BAA+B,OAAO;AAAA,IAClD,CAAC;AAAA,EACF;AACD,GAV8B;AAY9B,IAAO,2CAAQ;;;ACzBJ,IAAM,mCAAmC;AAAA,EAE9B;AAAA,EAAyB;AAC3C;AACA,IAAO,sCAAQ;;;ACcnB,IAAM,wBAAsC,CAAC;AAKtC,SAAS,uBAAuB,MAAqC;AAC3E,wBAAsB,KAAK,GAAG,KAAK,KAAK,CAAC;AAC1C;AAFgB;AAShB,SAAS,uBACR,SACAC,MACA,KACA,UACA,iBACsB;AACtB,QAAM,CAAC,MAAM,GAAG,IAAI,IAAI;AACxB,QAAM,gBAAmC;AAAA,IACxC;AAAA,IACA,KAAK,YAAY,QAAQ;AACxB,aAAO,uBAAuB,YAAY,QAAQ,KAAK,UAAU,IAAI;AAAA,IACtE;AAAA,EACD;AACA,SAAO,KAAK,SAASA,MAAK,KAAK,aAAa;AAC7C;AAfS;AAiBF,SAAS,kBACf,SACAA,MACA,KACA,UACA,iBACsB;AACtB,SAAO,uBAAuB,SAASA,MAAK,KAAK,UAAU;AAAA,IAC1D,GAAG;AAAA,IACH;AAAA,EACD,CAAC;AACF;AAXgB;;;AC3ChB,IAAM,iCAAN,MAAM,gCAA8D;AAAA,EAGnE,YACU,eACA,MACT,SACC;AAHQ;AACA;AAGT,SAAK,WAAW;AAAA,EACjB;AAAA,EArBD,OAYoE;AAAA;AAAA;AAAA,EAC1D;AAAA,EAUT,UAAU;AACT,QAAI,EAAE,gBAAgB,kCAAiC;AACtD,YAAM,IAAI,UAAU,oBAAoB;AAAA,IACzC;AAEA,SAAK,SAAS;AAAA,EACf;AACD;AAEA,SAAS,oBAAoB,QAA0C;AAEtE,MACC,qCAAqC,UACrC,iCAAiC,WAAW,GAC3C;AACD,WAAO;AAAA,EACR;AAEA,aAAW,cAAc,kCAAkC;AAC1D,wBAAoB,UAAU;AAAA,EAC/B;AAEA,QAAM,kBAA+C,gCACpD,SACAC,MACA,KACC;AACD,QAAI,OAAO,UAAU,QAAW;AAC/B,YAAM,IAAI,MAAM,6CAA6C;AAAA,IAC9D;AACA,WAAO,OAAO,MAAM,SAASA,MAAK,GAAG;AAAA,EACtC,GATqD;AAWrD,SAAO;AAAA,IACN,GAAG;AAAA,IACH,MAAM,SAASA,MAAK,KAAK;AACxB,YAAM,aAAyB,gCAAU,MAAM,MAAM;AACpD,YAAI,SAAS,eAAe,OAAO,cAAc,QAAW;AAC3D,gBAAM,aAAa,IAAI;AAAA,YACtB,KAAK,IAAI;AAAA,YACT,KAAK,QAAQ;AAAA,YACb,MAAM;AAAA,YAAC;AAAA,UACR;AACA,iBAAO,OAAO,UAAU,YAAYA,MAAK,GAAG;AAAA,QAC7C;AAAA,MACD,GAT+B;AAU/B,aAAO,kBAAkB,SAASA,MAAK,KAAK,YAAY,eAAe;AAAA,IACxE;AAAA,EACD;AACD;AAxCS;AA0CT,SAAS,qBACR,OAC8B;AAE9B,MACC,qCAAqC,UACrC,iCAAiC,WAAW,GAC3C;AACD,WAAO;AAAA,EACR;AAEA,aAAW,cAAc,kCAAkC;AAC1D,wBAAoB,UAAU;AAAA,EAC/B;AAGA,SAAO,cAAc,MAAM;AAAA,IAC1B,mBAAyE,wBACxE,SACAA,MACA,QACI;AACJ,WAAK,MAAMA;AACX,WAAK,MAAM;AACX,UAAI,MAAM,UAAU,QAAW;AAC9B,cAAM,IAAI,MAAM,sDAAsD;AAAA,MACvE;AACA,aAAO,MAAM,MAAM,OAAO;AAAA,IAC3B,GAXyE;AAAA,IAazE,cAA0B,wBAAC,MAAM,SAAS;AACzC,UAAI,SAAS,eAAe,MAAM,cAAc,QAAW;AAC1D,cAAM,aAAa,IAAI;AAAA,UACtB,KAAK,IAAI;AAAA,UACT,KAAK,QAAQ;AAAA,UACb,MAAM;AAAA,UAAC;AAAA,QACR;AACA,eAAO,MAAM,UAAU,UAAU;AAAA,MAClC;AAAA,IACD,GAT0B;AAAA,IAW1B,MAAM,SAAwD;AAC7D,aAAO;AAAA,QACN;AAAA,QACA,KAAK;AAAA,QACL,KAAK;AAAA,QACL,KAAK;AAAA,QACL,KAAK;AAAA,MACN;AAAA,IACD;AAAA,EACD;AACD;AAnDS;AAqDT,IAAI;AACJ,IAAI,OAAO,wCAAU,UAAU;AAC9B,kBAAgB,oBAAoB,mCAAK;AAC1C,WAAW,OAAO,wCAAU,YAAY;AACvC,kBAAgB,qBAAqB,mCAAK;AAC3C;AACA,IAAO,kCAAQ;",
  "names": ["PerformanceMark", "clear", "count", "countReset", "createTask", "debug", "dir", "dirxml", "error", "group", "groupCollapsed", "groupEnd", "info", "log", "profile", "profileEnd", "table", "time", "timeEnd", "timeLog", "timeStamp", "trace", "warn", "hrtime", "dir", "env", "count", "cwd", "hrtime", "assert", "env", "env", "env", "context", "env", "title", "env", "count", "env", "error", "env", "error", "count", "env", "env", "error", "env", "env"]
}
